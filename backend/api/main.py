"""API FastAPI para Detec√ß√£o de PII - Participa DF.

Sistema de detec√ß√£o de Informa√ß√µes Pessoalmente Identific√°veis (PII) para
manifesta√ß√µes do Participa DF em conformidade com LGPD (Lei Geral de Prote√ß√£o
de Dados) e LAI (Lei de Acesso √† Informa√ß√£o).

Endpoints:
    POST /analyze: Analisa texto para detec√ß√£o de PII
    GET /health: Verifica status da API
    POST /api/lote: Enfileira processamento de lote (CSV/XLSX)
    GET /api/lote/status/{job_id}: Consulta status do processamento de lote
    GET /api/lote/download/{job_id}: Faz download do resultado do lote

Contexto:
    - Detecta PII em manifesta√ß√µes de cidad√£os (reclama√ß√µes, sugest√µes, den√∫ncias)
    - Protege dados privados enquanto preserva informa√ß√µes p√∫blicas (LAI)
    - Implementa imunidade funcional para agentes p√∫blicos em exerc√≠cio

Exemplo de uso:
    >>> import requests
    >>> response = requests.post(
    ...     "http://localhost:8000/analyze",
    ...     json={"text": "Meu CPF √© 123.456.789-09", "id": "manifestacao_123"}
    ... )
    >>> print(response.json())
    {
        "id": "manifestacao_123",
        "classificacao": "N√ÉO P√öBLICO",
        "risco": "CR√çTICO",
        "confianca": 1.0,  # ‚úÖ NORMALIZADO 0-1
        "detalhes": [{"tipo": "CPF", "valor": "123.456.789-09", ...}]
    }
"""

import logging
logging.basicConfig(level=logging.DEBUG)

# Corrige PYTHONPATH para garantir importa√ß√£o tanto local quanto no HF Spaces
import sys, os
# Adiciona diret√≥rio pai (backend/) ao path
backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, backend_dir)
# Adiciona diret√≥rio raiz (para imports com 'backend.')
sys.path.insert(0, os.path.dirname(backend_dir))

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

from typing import Dict, Optional, List
from fastapi import FastAPI, UploadFile, File, Request, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uuid

# Imports com fallback para HF Spaces (sem prefixo 'backend.')
try:
    from backend.api.celery_config import celery_app
    from backend.src.detector import PIIDetector
except ModuleNotFoundError:
    from api.celery_config import celery_app
    from src.detector import PIIDetector

from celery.result import AsyncResult
import json
import threading
from datetime import datetime
import shutil
import atexit

# === HUGGINGFACE HUB PARA PERSIST√äNCIA ===
try:
    from huggingface_hub import hf_hub_download, HfApi
    HF_HUB_AVAILABLE = True
except ImportError:
    HF_HUB_AVAILABLE = False
    print("‚ö†Ô∏è huggingface_hub n√£o dispon√≠vel - usando storage local")

# Configura√ß√£o do HF Dataset para persist√™ncia
HF_TOKEN = os.environ.get("HF_TOKEN")
HF_STATS_REPO = os.environ.get("HF_STATS_REPO", "marinhothiago/desafio-participa-df")
USE_HF_STORAGE = HF_HUB_AVAILABLE and HF_TOKEN is not None

if USE_HF_STORAGE:
    print(f"‚úÖ Persist√™ncia HuggingFace ativada: {HF_STATS_REPO}")
    print(f"   üì¶ Modo BATCH: commits a cada 5 minutos (evita rate limit)")
else:
    print("üìÅ Usando storage local (HF_TOKEN n√£o configurado)")

# === SISTEMA DE CONTADORES GLOBAIS ===
STATS_FILE = os.path.join(backend_dir, "data", "stats.json")
FEEDBACK_FILE = os.path.join(backend_dir, "data", "feedback.json")
TRAINING_STATUS_FILE = os.path.join(backend_dir, "data", "training_status.json")
stats_lock = threading.Lock()
feedback_lock = threading.Lock()

# Cache local para reduzir chamadas ao HF
_stats_cache: Dict = None
_stats_cache_time: float = 0
_feedback_cache: Dict = None
_feedback_cache_time: float = 0
STATS_CACHE_TTL = 60  # segundos
FEEDBACK_CACHE_TTL = 30  # segundos

# === SISTEMA DE BATCH PARA HF (evita rate limit de 128 commits/hora) ===
_pending_hf_sync: Dict[str, bool] = {"stats.json": False, "feedback.json": False}
_last_hf_sync: float = 0
HF_SYNC_INTERVAL = 300  # 5 minutos entre commits (m√°x 12/hora)
_sync_lock = threading.Lock()

def _sync_to_hf_if_needed(force: bool = False) -> None:
    """Sincroniza arquivos pendentes com HF Dataset (batch)."""
    global _last_hf_sync, _pending_hf_sync
    import time
    
    if not USE_HF_STORAGE:
        return
    
    with _sync_lock:
        now = time.time()
        time_since_last = now - _last_hf_sync
        
        # S√≥ sincroniza se passou tempo suficiente ou for√ßado
        if not force and time_since_last < HF_SYNC_INTERVAL:
            return
        
        # Verifica se h√° algo pendente
        files_to_sync = [f for f, pending in _pending_hf_sync.items() if pending]
        if not files_to_sync:
            return
        
        print(f"üîÑ Sincronizando {len(files_to_sync)} arquivo(s) com HuggingFace...")
        
        try:
            import tempfile
            api = HfApi(token=HF_TOKEN)
            
            # Prepara arquivos para upload em batch
            operations = []
            for filename in files_to_sync:
                local_path = STATS_FILE if filename == "stats.json" else FEEDBACK_FILE
                if os.path.exists(local_path):
                    with open(local_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # Cria arquivo tempor√°rio
                    temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False, encoding='utf-8')
                    json.dump(data, temp_file, indent=2, ensure_ascii=False)
                    temp_file.close()
                    
                    from huggingface_hub import CommitOperationAdd
                    operations.append(CommitOperationAdd(
                        path_in_repo=filename,
                        path_or_fileobj=temp_file.name
                    ))
            
            if operations:
                # Commit √∫nico com todos os arquivos
                stats = _stats_cache or {}
                api.create_commit(
                    repo_id=HF_STATS_REPO,
                    repo_type="dataset",
                    operations=operations,
                    commit_message=f"Batch sync: {stats.get('site_visits', 0)} visits, {stats.get('classification_requests', 0)} requests"
                )
                
                # Limpa arquivos tempor√°rios
                for op in operations:
                    try:
                        os.unlink(op.path_or_fileobj)
                    except:
                        pass
                
                # Marca como sincronizado
                for filename in files_to_sync:
                    _pending_hf_sync[filename] = False
                
                _last_hf_sync = now
                print(f"‚úÖ Sincronizado com HuggingFace: {', '.join(files_to_sync)}")
        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao sincronizar com HF: {e}")

def _mark_pending_sync(filename: str) -> None:
    """Marca arquivo como pendente de sincroniza√ß√£o."""
    global _pending_hf_sync
    _pending_hf_sync[filename] = True
    # Tenta sincronizar (s√≥ vai se passou tempo suficiente)
    _sync_to_hf_if_needed()

def _force_sync_on_shutdown() -> None:
    """For√ßa sincroniza√ß√£o ao encerrar a aplica√ß√£o."""
    print("üõë Encerrando - sincronizando dados pendentes...")
    _sync_to_hf_if_needed(force=True)

# Registra sincroniza√ß√£o ao encerrar
atexit.register(_force_sync_on_shutdown)

def _load_from_hf(filename: str) -> Dict:
    """Carrega arquivo JSON do HuggingFace Dataset."""
    try:
        path = hf_hub_download(
            repo_id=HF_STATS_REPO,
            filename=filename,
            repo_type="dataset",
            token=HF_TOKEN
        )
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar {filename} do HF: {e}")
        return None

def load_stats() -> Dict:
    """Carrega estat√≠sticas (cache > local > HF)."""
    global _stats_cache, _stats_cache_time
    import time
    
    # Verifica cache primeiro
    if _stats_cache is not None and (time.time() - _stats_cache_time) < STATS_CACHE_TTL:
        return _stats_cache.copy()
    
    stats = None
    
    # Tenta carregar do arquivo local primeiro (mais r√°pido)
    try:
        if os.path.exists(STATS_FILE):
            with open(STATS_FILE, 'r') as f:
                stats = json.load(f)
    except Exception as e:
        print(f"Erro ao carregar stats local: {e}")
    
    # Fallback para HF se local n√£o existe
    if stats is None and USE_HF_STORAGE:
        stats = _load_from_hf("stats.json")
        # Salva localmente para pr√≥ximas leituras
        if stats:
            try:
                os.makedirs(os.path.dirname(STATS_FILE), exist_ok=True)
                with open(STATS_FILE, 'w') as f:
                    json.dump(stats, f, indent=2)
            except:
                pass
    
    if stats is None:
        stats = {"site_visits": 0, "classification_requests": 0, "last_updated": None}
    
    # Atualiza cache
    _stats_cache = stats.copy()
    _stats_cache_time = time.time()
    
    return stats

def save_stats(stats: Dict) -> None:
    """Salva estat√≠sticas (local imediato + HF em batch)."""
    global _stats_cache, _stats_cache_time
    import time
    
    stats["last_updated"] = datetime.now().isoformat()
    
    # Sempre salva localmente (imediato)
    try:
        os.makedirs(os.path.dirname(STATS_FILE), exist_ok=True)
        with open(STATS_FILE, 'w') as f:
            json.dump(stats, f, indent=2)
    except Exception as e:
        print(f"Erro ao salvar stats local: {e}")
    
    # Marca para sincroniza√ß√£o em batch com HF
    if USE_HF_STORAGE:
        _mark_pending_sync("stats.json")
    
    # Atualiza cache
    _stats_cache = stats.copy()
    _stats_cache_time = time.time()

def increment_stat(key: str, amount: int = 1) -> Dict:
    """Incrementa uma estat√≠stica de forma thread-safe."""
    with stats_lock:
        stats = load_stats()
        stats[key] = stats.get(key, 0) + amount
        save_stats(stats)
        return stats


# === SISTEMA DE FEEDBACK HUMANO ===
def load_feedback() -> Dict:
    """Carrega feedbacks (cache > local > HF)."""
    global _feedback_cache, _feedback_cache_time
    import time
    
    # Verifica cache primeiro
    if _feedback_cache is not None and (time.time() - _feedback_cache_time) < FEEDBACK_CACHE_TTL:
        return _feedback_cache.copy()
    
    data = None
    
    # Tenta carregar do arquivo local primeiro (mais r√°pido)
    try:
        if os.path.exists(FEEDBACK_FILE):
            with open(FEEDBACK_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
    except Exception as e:
        print(f"Erro ao carregar feedback local: {e}")
    
    # Fallback para HF se local n√£o existe
    if data is None and USE_HF_STORAGE:
        data = _load_from_hf("feedback.json")
        # Salva localmente para pr√≥ximas leituras
        if data:
            try:
                os.makedirs(os.path.dirname(FEEDBACK_FILE), exist_ok=True)
                with open(FEEDBACK_FILE, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2, ensure_ascii=False)
            except:
                pass
    
    if data is None:
        data = {
            "feedbacks": [],
            "stats": {
                "total_feedbacks": 0,
                "total_entities_reviewed": 0,
                "correct": 0,
                "incorrect": 0,
                "partial": 0,
                "by_type": {}
            },
            "last_updated": None
        }
    
    # Atualiza cache
    _feedback_cache = data.copy()
    _feedback_cache_time = time.time()
    
    return data


def save_feedback(data: Dict) -> None:
    """Salva feedbacks (local imediato + HF em batch)."""
    global _feedback_cache, _feedback_cache_time
    import time
    
    data["last_updated"] = datetime.now().isoformat()
    
    # Sempre salva localmente (imediato)
    try:
        os.makedirs(os.path.dirname(FEEDBACK_FILE), exist_ok=True)
        with open(FEEDBACK_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"Erro ao salvar feedback local: {e}")
    
    # Marca para sincroniza√ß√£o em batch com HF
    if USE_HF_STORAGE:
        _mark_pending_sync("feedback.json")
    
    # Atualiza cache
    _feedback_cache = data.copy()
    _feedback_cache_time = time.time()


def add_feedback(feedback_entry: Dict) -> Dict:
    """Adiciona um feedback e atualiza estat√≠sticas."""
    with feedback_lock:
        data = load_feedback()
        
        # Adiciona o feedback
        data["feedbacks"].append(feedback_entry)
        data["stats"]["total_feedbacks"] += 1
        
        # Atualiza estat√≠sticas por entidade
        for entity_fb in feedback_entry.get("entity_feedbacks", []):
            data["stats"]["total_entities_reviewed"] += 1
            validacao = entity_fb.get("validacao_humana", "").upper()
            
            if validacao == "CORRETO":
                data["stats"]["correct"] += 1
            elif validacao == "INCORRETO":
                data["stats"]["incorrect"] += 1
            elif validacao == "PARCIAL":
                data["stats"]["partial"] += 1
            
            # Estat√≠sticas por tipo de entidade
            tipo = entity_fb.get("tipo", "UNKNOWN")
            if tipo not in data["stats"]["by_type"]:
                data["stats"]["by_type"][tipo] = {"correct": 0, "incorrect": 0, "partial": 0, "total": 0}
            
            data["stats"]["by_type"][tipo]["total"] += 1
            if validacao == "CORRETO":
                data["stats"]["by_type"][tipo]["correct"] += 1
            elif validacao == "INCORRETO":
                data["stats"]["by_type"][tipo]["incorrect"] += 1
            elif validacao == "PARCIAL":
                data["stats"]["by_type"][tipo]["partial"] += 1
        
        save_feedback(data)
        
        # Calcula accuracy para retorno
        total = data["stats"]["total_entities_reviewed"]
        correct = data["stats"]["correct"]
        accuracy = correct / total if total > 0 else 0
        
        return {
            **data["stats"],
            "accuracy": round(accuracy, 4)
        }


# === MODELOS PYDANTIC PARA FEEDBACK ===
class EntityFeedback(BaseModel):
    tipo: str
    valor: str
    confianca_modelo: float
    fonte: Optional[str] = "unknown"
    validacao_humana: str  # CORRETO | INCORRETO | PARCIAL
    tipo_corrigido: Optional[str] = None
    comentario: Optional[str] = None


class FeedbackRequest(BaseModel):
    analysis_id: Optional[str] = None
    original_text: str
    entity_feedbacks: List[EntityFeedback]
    classificacao_modelo: str
    classificacao_corrigida: Optional[str] = None
    revisor: Optional[str] = "anonymous"

# Inicializa aplica√ß√£o FastAPI
app = FastAPI(
    title="Participa DF - PII Detector API",
    description="API para detec√ß√£o de Informa√ß√µes Pessoais Identific√°veis em textos segundo LGPD/LAI",
    version="9.5.0"
)

# Configura√ß√£o CORS: Permite requisi√ß√µes de qualquer origem (necess√°rio para frontend React/Vite)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inicializa detector PII na mem√≥ria (carregamento √∫nico de modelos)
# LLAMA-3.2-3B √ÅRBITRO: Desativado por padr√£o para evitar custos
# Ative via env PII_USE_LLM_ARBITRATION=True se tiver HF_TOKEN configurado
import os
usar_gpu = os.getenv("PII_USAR_GPU", "True").lower() == "true"
use_llm_arbitration = os.getenv("PII_USE_LLM_ARBITRATION", "False").lower() == "true"
detector = PIIDetector(
    usar_gpu=usar_gpu,
    use_llm_arbitration=use_llm_arbitration
)



from src.confidence.combiners import merge_spans_custom

@app.post("/analyze")
async def analyze(
    request: Request,
    data: Dict[str, Optional[str]],
    merge_preset: str = Query(
        default="f1",
        description="Estrat√©gia de merge de spans: 'recall', 'precision', 'f1', 'custom'."
    ),
    use_llm: bool = Query(
        default=False,
        description="For√ßa uso do √°rbitro LLM para arbitragem de PII."
    )
) -> Dict:
    """
    Analisa texto para detec√ß√£o de PII com contexto Bras√≠lia/GDF.
    Permite selecionar estrat√©gia de merge de spans via par√¢metro merge_preset.
    """
    # Log para debug de requisi√ß√µes
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    text_preview = data.get("text", "")[:50].replace("\n", " ") if data.get("text") else ""
    logging.info(f"üìä POST /analyze | IP: {client_ip} | UA: {user_agent[:60]} | Text: '{text_preview}...'")
    
    text = data.get("text", "")
    request_id = data.get("id", None)

    # Executa detec√ß√£o usando detector h√≠brido
    has_pii, findings, risco, confianca = detector.detect(text, force_llm=use_llm)

    # Estrat√©gias de merge
    if findings:
        if merge_preset == "recall":
            criterio = "longest"
            tie_breaker = "all"
        elif merge_preset == "precision":
            criterio = "score"
            tie_breaker = "leftmost"
        elif merge_preset == "f1":
            criterio = "longest"
            tie_breaker = "leftmost"
        elif merge_preset == "custom":
            criterio = "custom"
            tie_breaker = "leftmost"
        else:
            criterio = "longest"
            tie_breaker = "leftmost"
        # TODO: aplicar merge_spans_custom se necess√°rio

    # Incrementa contador de requisi√ß√µes (global)
    increment_stat("classification_requests")

    # Retorna resultado no formato documentado (compat√≠vel com frontend)
    return {
        "id": request_id,
        # Formato novo (documentado no README)
        "has_pii": has_pii,
        "entities": findings,
        "risk_level": risco,
        "confidence_all_found": confianca,
        "total_entities": len(findings) if findings else 0,
        "sources_used": list(set(f.get("fonte", "regex") for f in findings)) if findings else [],
        # Formato legado (para retrocompatibilidade)
        "classificacao": "N√ÉO P√öBLICO" if has_pii else "P√öBLICO",
        "risco": risco,
        "confianca": confianca,
        "detalhes": findings
    }


@app.get("/stats")
async def get_stats() -> Dict:
    """Retorna estat√≠sticas globais de uso da API.
    
    Returns:
        Dict com:
            - site_visits (int): Total de visitas ao site
            - classification_requests (int): Total de textos analisados
            - last_updated (str): Data/hora da √∫ltima atualiza√ß√£o
    """
    return load_stats()


@app.post("/stats/visit")
async def register_visit() -> Dict:
    """Registra uma nova visita ao site.
    
    Deve ser chamado uma vez por sess√£o do usu√°rio.
    
    Returns:
        Dict com estat√≠sticas atualizadas
    """
    return increment_stat("site_visits")


# === ENDPOINTS DE FEEDBACK HUMANO ===
@app.post("/feedback")
async def submit_feedback(feedback: FeedbackRequest) -> Dict:
    """Submete valida√ß√£o humana de uma an√°lise de PII.
    
    Permite que revisores validem se as entidades detectadas s√£o realmente PII.
    
    Args:
        feedback: Objeto com valida√ß√µes das entidades detectadas
        
    Returns:
        Dict com:
            - feedback_id: ID √∫nico do feedback
            - stats: Estat√≠sticas atualizadas de acur√°cia
    """
    feedback_entry = {
        "feedback_id": str(uuid.uuid4()),
        "analysis_id": feedback.analysis_id,
        "timestamp": datetime.now().isoformat(),
        "original_text": feedback.original_text[:500],  # Limita tamanho
        "entity_feedbacks": [ef.dict() for ef in feedback.entity_feedbacks],
        "classificacao_modelo": feedback.classificacao_modelo,
        "classificacao_corrigida": feedback.classificacao_corrigida,
        "revisor": feedback.revisor
    }
    
    stats = add_feedback(feedback_entry)
    
    # ‚ú® Recalibra√ß√£o autom√°tica a cada feedback
    try:
        try:
            from src.confidence.auto_recalibrate import recalibrate_from_feedbacks
        except ImportError:
            from backend.src.confidence.auto_recalibrate import recalibrate_from_feedbacks
        
        feedback_data = load_feedback()
        total_fb = len(feedback_data.get("feedbacks", []))
        logging.info(f"üì• Recalibra√ß√£o: {total_fb} feedbacks total no arquivo")
        
        recalibration_result = recalibrate_from_feedbacks(feedback_data)
        logging.info(f"üîÑ Recalibra√ß√£o autom√°tica: {recalibration_result.get('message')}")
        if recalibration_result.get('success'):
            logging.info(f"   ‚úÖ {recalibration_result.get('total_samples')} amostras processadas")
            logging.info(f"   üìä By source: {recalibration_result.get('by_source')}")
    except Exception as e:
        import traceback
        logging.error(f"‚ùå Erro na recalibra√ß√£o autom√°tica: {e}")
        logging.error(traceback.format_exc())
    
    return {
        "feedback_id": feedback_entry["feedback_id"],
        "message": "Feedback registrado com sucesso",
        "stats": stats
    }


@app.get("/feedback/stats")
async def get_feedback_stats() -> Dict:
    """Retorna estat√≠sticas de acur√°cia baseadas no feedback humano.
    
    Returns:
        Dict com:
            - total_feedbacks: Total de an√°lises revisadas
            - total_entities_reviewed: Total de entidades validadas
            - accuracy: Taxa de acertos do modelo (correct / total)
            - false_positive_rate: Taxa de falsos positivos
            - by_type: Estat√≠sticas por tipo de entidade
    """
    data = load_feedback()
    stats = data.get("stats", {})
    
    total = stats.get("total_entities_reviewed", 0)
    correct = stats.get("correct", 0)
    incorrect = stats.get("incorrect", 0)
    
    # Calcula m√©tricas
    accuracy = correct / total if total > 0 else 0
    false_positive_rate = incorrect / total if total > 0 else 0
    
    # Calcula acur√°cia por tipo
    by_type_with_accuracy = {}
    for tipo, tipo_stats in stats.get("by_type", {}).items():
        tipo_total = tipo_stats.get("total", 0)
        tipo_correct = tipo_stats.get("correct", 0)
        tipo_incorrect = tipo_stats.get("incorrect", 0)
        by_type_with_accuracy[tipo] = {
            **tipo_stats,
            "accuracy": tipo_correct / tipo_total if tipo_total > 0 else 0,
            "false_positive_rate": tipo_incorrect / tipo_total if tipo_total > 0 else 0
        }
    
    return {
        "total_feedbacks": stats.get("total_feedbacks", 0),
        "total_entities_reviewed": total,
        "correct": correct,
        "incorrect": incorrect,
        "partial": stats.get("partial", 0),
        "accuracy": round(accuracy, 4),
        "false_positive_rate": round(false_positive_rate, 4),
        "by_type": by_type_with_accuracy,
        "last_updated": data.get("last_updated")
    }


@app.get("/feedback/export")
async def export_feedback() -> Dict:
    """Exporta todos os feedbacks para dataset de treinamento.
    
    Returns:
        Dict com lista completa de feedbacks e estat√≠sticas
    """
    data = load_feedback()
    return {
        "total_records": len(data.get("feedbacks", [])),
        "feedbacks": data.get("feedbacks", []),
        "stats": data.get("stats", {}),
        "exported_at": datetime.now().isoformat()
    }


@app.post("/feedback/generate-dataset")
async def generate_dataset(format: str = "jsonl") -> Dict:
    """Gera dataset de treinamento a partir dos feedbacks coletados.
    
    Transforma feedbacks em formato pronto para:
    1. Fine-tuning de modelos NER
    2. Treinamento de calibradores de confian√ßa
    3. An√°lise de padr√µes de erro
    
    Args:
        format: 'jsonl' ou 'csv'
    
    Returns:
        Dict com caminho do arquivo gerado e estat√≠sticas
    """
    try:
        from scripts.feedback_to_dataset import (
            export_ner_dataset_jsonl, 
            export_ner_dataset_csv,
            generate_ner_dataset
        )
        
        if format == "csv":
            output_path = export_ner_dataset_csv()
        else:  # jsonl (padr√£o)
            output_path = export_ner_dataset_jsonl()
        
        samples, stats = generate_ner_dataset()
        
        return {
            "success": True,
            "message": f"Dataset gerado em formato {format}",
            "output_file": output_path,
            "stats": stats,
            "generated_at": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "generated_at": datetime.now().isoformat()
        }


@app.get("/feedback/dataset-stats")
async def get_dataset_stats() -> Dict:
    """Retorna estat√≠sticas do dataset que seria gerado para treinamento.
    
    √ötil para saber se h√° dados suficientes antes de disparar treinamento.
    
    Returns:
        Dict com:
            - total_samples: Quantas amostras de treinamento
            - by_type: Distribui√ß√£o por tipo de entidade
            - min_samples_for_training: M√≠nimo recomendado
            - ready_for_training: Boolean
    """
    try:
        from scripts.feedback_to_dataset import generate_ner_dataset
        samples, stats = generate_ner_dataset()
        
        min_samples_recommended = 50
        is_ready = len(samples) >= min_samples_recommended
        
        return {
            **stats,
            "min_samples_recommended": min_samples_recommended,
            "ready_for_training": is_ready,
            "recommendation": (
                "‚úÖ Dados suficientes! Pronto para treinamento." if is_ready
                else f"‚ùå Precisa de mais {min_samples_recommended - len(samples)} amostras"
            )
        }
    except Exception as e:
        return {
            "error": str(e),
            "total_samples": 0,
            "ready_for_training": False
        }


@app.get("/feedback/training-status")
async def get_training_status() -> Dict:
    """Retorna status de treinamento e calibra√ß√£o autom√°tica.
    
    Combina dados de:
    - feedback.json: Estat√≠sticas de feedback dos usu√°rios (persistente)
    - training_status.json: Hist√≥rico de calibra√ß√£o do modelo
    
    Mostra:
    - Total de feedbacks coletados
    - Acur√°cia do modelo baseada em feedback humano
    - Distribui√ß√£o de valida√ß√µes (correto/incorreto/parcial)
    - Estat√≠sticas por tipo de PII
    - Recomenda√ß√µes autom√°ticas
    
    Returns:
        Dict com status completo do treinamento
    """
    try:
        # Carregar estat√≠sticas de feedback (persistentes)
        feedback_data = load_feedback()
        stats = feedback_data.get("stats", {})
        
        total_entities = stats.get("total_entities_reviewed", 0)
        correct = stats.get("correct", 0)
        incorrect = stats.get("incorrect", 0)
        partial = stats.get("partial", 0)
        
        # Calcular acur√°cia baseada em feedback humano
        accuracy = correct / total_entities if total_entities > 0 else 0
        
        # Gerar status baseado na quantidade de dados
        if total_entities == 0:
            status = "never_trained"
            time_since_last = "Nenhum feedback ainda"
        elif total_entities < 20:
            status = "learning"
            time_since_last = f"{total_entities} feedbacks coletados"
        elif total_entities < 50:
            status = "improving"
            time_since_last = f"{total_entities} feedbacks coletados"
        else:
            status = "ready" if accuracy >= 0.85 else "needs_attention"
            time_since_last = f"{total_entities} feedbacks coletados"
        
        # Gerar recomenda√ß√µes din√¢micas
        recommendations = []
        
        if total_entities == 0:
            recommendations.append({
                "type": "get_started",
                "message": "üìù Comece a avaliar detec√ß√µes para treinar o modelo",
                "action": "Use o painel de feedback nas an√°lises",
            })
        elif total_entities < 20:
            needed = 20 - total_entities
            recommendations.append({
                "type": "collect_more_data",
                "message": f"üìä Precisamos de mais {needed} avalia√ß√µes para calibra√ß√£o inicial",
                "action": "Continue avaliando detec√ß√µes",
            })
        elif total_entities < 50:
            needed = 50 - total_entities
            recommendations.append({
                "type": "collect_more_data",
                "message": f"üìä Mais {needed} avalia√ß√µes para treinamento robusto",
                "action": "Continue coletando feedbacks",
            })
        
        if accuracy < 0.85 and total_entities >= 20:
            recommendations.append({
                "type": "needs_attention",
                "message": f"‚ö†Ô∏è Acur√°cia atual: {accuracy*100:.1f}%. Investigar tipos problem√°ticos.",
                "action": "Revisar tipos com mais erros",
            })
        
        if accuracy >= 0.90 and total_entities >= 50:
            recommendations.append({
                "type": "ready_for_finetuning",
                "message": "‚úÖ Dados suficientes e acur√°cia boa! Modelo calibrado.",
                "action": "Sistema pronto para uso em produ√ß√£o",
            })
        
        # Tentar carregar tamb√©m o training_status.json (calibra√ß√£o manual)
        training_data = {}
        try:
            try:
                from src.confidence.training import get_training_tracker
            except ImportError:
                from backend.src.confidence.training import get_training_tracker
            
            tracker = get_training_tracker()
            training_data = tracker.data
        except Exception:
            pass
        
        return {
            "status": status,
            "last_calibration": training_data.get("last_calibration"),
            "total_samples_used": total_entities,
            "total_feedbacks": stats.get("total_feedbacks", 0),
            "accuracy_before": training_data.get("accuracy_before", 0),
            "accuracy_after": accuracy,
            "improvement_percentage": round((accuracy - training_data.get("accuracy_before", 0)) * 100, 2) if accuracy > 0 else 0,
            "time_since_last": time_since_last,
            "by_source": stats.get("by_type", {}),
            "validation_breakdown": {
                "correct": correct,
                "incorrect": incorrect,
                "partial": partial,
            },
            "recommendations": recommendations,
        }
    except Exception as e:
        import traceback
        logger.error(f"Erro ao obter status de treinamento: {e}\n{traceback.format_exc()}")
        return {
            "error": str(e),
            "status": "error",
            "message": "Erro ao obter status de treinamento"
        }


@app.get("/health")
async def health() -> Dict[str, str]:
    """Verifica o status da API e disponibilidade dos modelos NLP.
    
    Endpoint de health check para monitoramento e orquestra√ß√£o de container.
    
    Returns:
        Dict com:
            - status (str): "healthy" se tudo funcionando
            - version (str): Vers√£o do detector (v9.4)
    
    HTTP Status Codes:
        - 200: API operacional
        - 503: Algum modelo NLP n√£o carregado (degraded mode)
    """
    return {
        "status": "healthy",
        "version": "9.4"
    }

@app.post('/api/lote')
def submit_lote(file: UploadFile = File(...)):
    """Enfileira processamento de lote (CSV/XLSX) e retorna job_id."""
    ext = file.filename.split('.')[-1].lower()
    tipo_arquivo = 'csv' if ext == 'csv' else 'xlsx' if ext in ['xlsx', 'xls'] else None
    if not tipo_arquivo:
        return {"erro": "Arquivo n√£o suportado"}
    temp_path = f'/tmp/{file.filename}'
    with open(temp_path, 'wb') as f:
        shutil.copyfileobj(file.file, f)
    task = celery_app.send_task('backend.celery_worker_tasks.processar_lote', args=[temp_path, tipo_arquivo])
    return {"job_id": task.id}

@app.get('/api/lote/status/{job_id}')
def get_lote_status(job_id: str):
    """Consulta status do processamento de lote."""
    res = AsyncResult(job_id, app=celery_app)
    return {"status": res.status, "result": res.result if res.successful() else None}

@app.get('/api/lote/download/{job_id}')
def download_lote_result(job_id: str):
    """Faz download do resultado do lote, se dispon√≠vel."""
    res = AsyncResult(job_id, app=celery_app)
    if not res.successful():
        return {"erro": "Resultado ainda n√£o dispon√≠vel"}
    path = res.result
    if not os.path.exists(path):
        return {"erro": "Arquivo n√£o encontrado"}
    return FileResponse(path, filename=os.path.basename(path))
