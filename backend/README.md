
---
title: Participa DF - Detector Inteligente de Dados Pessoais
emoji: üõ°Ô∏è
colorFrom: blue
colorTo: green
sdk: docker
app_file: app.py
pinned: false
---

## üöÄ MELHORIAS E FUNCIONALIDADES AVAN√áADAS (2025-2026)

- üèõÔ∏è **Gazetteer institucional GDF:** Filtro de falsos positivos para nomes de √≥rg√£os, escolas, hospitais e aliases do DF, edit√°vel via `src/gazetteer_gdf.json`. Garante m√°xima precis√£o em contexto Bras√≠lia/DF.
- üß† **Sistema de confian√ßa probabil√≠stica:** Calibra√ß√£o isot√¥nica + log-odds, thresholds din√¢micos por tipo, fatores de contexto, explica√ß√£o detalhada abaixo.
- ‚ö° **P√≥s-processamento de spans:** Normaliza√ß√£o, merge/split, deduplica√ß√£o de entidades para m√°xima precis√£o, via `pos_processar_spans.py`.
- üèÜ **Benchmark LGPD/LAI:** 318+ casos reais, F1-score 0.9763, todos FPs/FNs conhecidos e documentados.
- üîí **Seguran√ßa do token Hugging Face:** Uso obrigat√≥rio de `.env` (n√£o versionado), carregamento autom√°tico em todos os entrypoints, nunca exposto em c√≥digo ou log.
- üßπ **Limpeza e organiza√ß√£o:** `.gitignore` e `.dockerignore` revisados, scripts de limpeza, deploy seguro, documenta√ß√£o atualizada.
- üê≥ **Deploy profissional:** Docker Compose, Hugging Face Spaces, checklist de produ√ß√£o.
- üõ†Ô∏è **Otimizador de ensemble:** `optimize_ensemble.py` para grid search de pesos do ensemble, reuso de detector, e valida√ß√£o autom√°tica.

---
## üÜï Estrat√©gias de Merge de Spans (Presets)

A partir da vers√£o 9.4.3, o endpoint `/analyze` permite escolher a estrat√©gia de merge de spans (entidades sobrepostas) via par√¢metro `merge_preset`:

- `recall`: Mant√©m todos os spans sobrepostos (maximiza recall, √∫til para auditoria).
- `precision`: Mant√©m apenas o span com maior score/confian√ßa (maximiza precis√£o, √∫til para produ√ß√£o).
- `f1`: Mant√©m o span mais longo por sobreposi√ß√£o (equil√≠brio entre recall e precis√£o, padr√£o).
- `custom`: Permite l√≥gica customizada (exemplo: priorizar fonte espec√≠fica ou l√≥gica pr√≥pria).

### Como usar na API

```http
POST /analyze?merge_preset=recall
Content-Type: application/json
{
  "text": "Meu CPF √© 123.456.789-09 e meu telefone √© 99999-8888"
}
```

- `merge_preset` pode ser: `recall`, `precision`, `f1`, `custom` (default: `f1`)
- O resultado em `detalhes` refletir√° a estrat√©gia escolhida.

### Exemplos de uso via curl

```bash
# Maximizar recall (todos spans):

# Maximizar precis√£o (apenas maior score):
curl -X POST "http://localhost:8000/analyze?merge_preset=precision" -H "Content-Type: application/json" -d '{"text": "Meu CPF √© 123.456.789-09"}'

# Customizado:
```

### Observa√ß√µes
- O merge s√≥ √© aplicado se as entidades retornadas tiverem `start` e `end` (posi√ß√£o no texto).
- Para uso avan√ßado, consulte `src/confidence/combiners.py` e ajuste a fun√ß√£o `merge_spans_custom`.
- O preset `custom` pode ser expandido para l√≥gica pr√≥pria no backend.

---
# üìö COMO USAR AS NOVAS FUNCIONALIDADES
### Gazetteer GDF
- Edite `src/gazetteer_gdf.json` para adicionar √≥rg√£os, escolas, hospitais, programas ou aliases. O detector ignora entidades que batem com o gazetteer, reduzindo FPs em contexto institucional.

- Execute `python optimize_ensemble.py` para buscar os melhores pesos do ensemble. O script reusa o detector e valida o F1-score automaticamente.
### Seguran√ßa do Token Hugging Face
- Crie um `.env` (N√ÉO versionado) com `HF_TOKEN=seu_token`. O backend carrega automaticamente. Nunca exponha o token em c√≥digo ou log.

- [x] `.env` nunca versionado
- [x] Modelos baixados no build do Docker
- [x] Scripts de limpeza n√£o v√£o para produ√ß√£o
- [x] Testes e benchmark executados antes do deploy
```bash
python main_cli.py --input data/input/manifestacoes.xlsx --output data/output/resultado

# Rodar benchmark completo

python pos_processar_spans.py --input data/output/resultado.json --output data/output/resultado_pos.json
```

---
---
emoji: üõ°Ô∏è
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# üõ°Ô∏è Backend: Motor PII Participa DF

## üîí Seguran√ßa do Token Hugging Face (HF_TOKEN)

> **IMPORTANTE:**
> - O token Hugging Face **NUNCA** deve ser colocado no c√≥digo-fonte nem em arquivos versionados (ex: .env, settings.py, etc).
> - Use sempre o arquivo `.env` (N√ÉO versionado) para armazenar o token localmente ou no deploy.
> - O arquivo `.env.example` serve apenas de modelo e pode ir para o GitHub, mas sem o token real.
> - O backend j√° l√™ automaticamente o `.env` e injeta o token no pipeline do transformers.
> - No deploy Hugging Face Spaces, configure o token como vari√°vel de ambiente ou suba um `.env` manualmente (N√ÉO envie para o reposit√≥rio).

**Resumo:**
- O token √© lido em tempo de execu√ß√£o, nunca aparece no log nem no c√≥digo.
- O projeto est√° seguro para uso p√∫blico e privado, desde que siga essas orienta√ß√µes.

## üÜï Integra√ß√£o Gazetteer GDF (v9.5)

O motor agora integra um **gazetteer institucional do GDF** (arquivo `gazetteer_gdf.json`) para filtrar falsos positivos de nomes, √≥rg√£os, escolas, hospitais e programas p√∫blicos. Isso garante que entidades institucional n√£o sejam marcadas como PII, elevando a precis√£o em contexto Bras√≠lia/DF.

**Como funciona:**
- O arquivo `src/gazetteer_gdf.json` cont√©m listas de √≥rg√£os, siglas, aliases, escolas e hospitais do GDF.
- O detector carrega todos os nomes/siglas/aliases e ignora qualquer entidade que bata exata ou parcialmente com o gazetteer.
- Logs informam quando uma entidade √© ignorada por match no gazetteer.

**Impacto no benchmark:**
- F1-Score mantido em 0.9763 (excelente, sem aumento de FP/FN)
- Nenhum novo falso positivo ou negativo foi introduzido
- Todos os FPs/FNs remanescentes s√£o casos conhecidos de padr√µes GDF, n√£o relacionados ao filtro institucional

**Como editar/expandir:**
- Edite `src/gazetteer_gdf.json` para adicionar novos √≥rg√£os, escolas, hospitais, programas ou aliases.
- O formato √© autoexplicativo e suporta m√∫ltiplos aliases por entidade.

**Exemplo de entrada:**
```json
{
    "orgaos": [
        {"nome": "Secretaria de Educa√ß√£o do DF", "sigla": "SEEDF", "aliases": ["Educa√ß√£o DF", "Secretaria Educa√ß√£o"]},
        {"nome": "DETRAN-DF", "sigla": "DETRAN", "aliases": ["Departamento de Tr√¢nsito"]}
    ],
    "escolas": [
        {"nome": "Centro de Ensino Fundamental 01 do Guar√°", "sigla": "CEF 01", "aliases": ["CEF Guar√°"]}
    ]
}
```

**Arquivo:** `backend/src/gazetteer_gdf.json`

---

[![Python](https://img.shields.io/badge/Python-3.10+-yellow?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![spaCy](https://img.shields.io/badge/spaCy-3.8.0-09A3D5?logo=spacy)](https://spacy.io/)
[![Vers√£o](https://img.shields.io/badge/Vers√£o-9.4.3-blue)](./src/detector.py)
[![F1--Score](https://img.shields.io/badge/F1--Score-1.0000-success)](./benchmark.py)

> **Motor h√≠brido de detec√ß√£o de Informa√ß√µes Pessoais Identific√°veis (PII)** para conformidade LGPD/LAI em manifesta√ß√µes do Participa DF.
> üèÜ **v9.4.3 - F1-Score = 1.0000** (100% precis√£o, 100% sensibilidade) em benchmark de 303 casos LGPD.
>
> üÜï **v9.4.3**: 5 n√≠veis de risco LGPD (CR√çTICO ‚Üí BAIXO), 30+ tipos de PII, IP/Coordenadas/User-Agent, contadores globais.

| üåê **Links de Produ√ß√£o** | URL |
|--------------------------|-----|
| API Base | https://marinhothiago-desafio-participa-df.hf.space/ |
| Documenta√ß√£o Interativa | https://marinhothiago-desafio-participa-df.hf.space/docs |
| Health Check | https://marinhothiago-desafio-participa-df.hf.space/health |

---

## üìã Objetivo do Backend

Detectar, classificar e avaliar o risco de vazamento de dados pessoais em textos de manifesta√ß√µes do Participa DF, retornando:

- **Classifica√ß√£o:** "P√öBLICO" ou "N√ÉO P√öBLICO"
- **N√≠vel de Risco:** SEGURO, BAIXO, MODERADO, ALTO, CR√çTICO (5 n√≠veis LGPD)
- **Confian√ßa:** Score normalizado (0.0 a 1.0)
- **Detalhes:** Lista de PIIs encontrados com tipo, valor e confian√ßa

### Funcionalidades Principais

- ‚úÖ **Rastreabilidade Total:** Preserva o ID original do e-SIC em todo o fluxo
- ‚úÖ **Motor H√≠brido v9.4.3:** Ensemble de Regex + BERT Davlan + NuNER + spaCy + Regras
- ‚úÖ **30+ Tipos de PII:** Documentos, contatos, financeiros, sa√∫de, biometria, localiza√ß√£o
- ‚úÖ **Confian√ßa Probabil√≠stica:** Calibra√ß√£o isot√¥nica + combina√ß√£o log-odds
- ‚úÖ **Tr√™s Formas de Uso:** API REST, Interface CLI (lote) e integra√ß√£o com Dashboard Web
- ‚úÖ **Valida√ß√£o de Documentos:** CPF, CNPJ, PIS, CNS com d√≠gito verificador
- ‚úÖ **Contexto Bras√≠lia/GDF:** Imunidade funcional para servidores p√∫blicos em exerc√≠cio
- ‚úÖ **Contadores Globais:** Persist√™ncia em stats.json com thread-safety

---

## üìÅ Estrutura de Arquivos e Fun√ß√£o de Cada Componente

```
backend/
‚îú‚îÄ‚îÄ README.md                 ‚Üê ESTE ARQUIVO: Documenta√ß√£o t√©cnica
‚îú‚îÄ‚îÄ requirements.txt          ‚Üê Depend√™ncias Python (pip install -r)
‚îú‚îÄ‚îÄ Dockerfile                ‚Üê Container para deploy em HuggingFace
‚îú‚îÄ‚îÄ docker-compose.yml        ‚Üê Orquestra√ß√£o local com frontend
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           ‚Üê Marca como m√≥dulo Python
‚îÇ   ‚îî‚îÄ‚îÄ main.py               ‚Üê FastAPI: endpoints /analyze e /health
‚îÇ                               (135 linhas, coment√°rios detalhados)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           ‚Üê Marca como m√≥dulo Python
‚îÇ   ‚îú‚îÄ‚îÄ detector.py           ‚Üê Motor h√≠brido PII v9.4.3
‚îÇ   ‚îÇ                           (2100+ linhas com coment√°rios explicativos)
‚îÇ   ‚îÇ                           - Classe PIIDetector: ensemble de detectores
‚îÇ   ‚îÇ                           - Classe ValidadorDocumentos: valida√ß√£o DV
‚îÇ   ‚îÇ                           - Regex patterns para 30+ tipos de PII
‚îÇ   ‚îÇ                           - NER: BERT Davlan + NuNER + spaCy
‚îÇ   ‚îÇ                           - Regras de neg√≥cio (imunidade funcional)
‚îÇ   ‚îÇ                           - M√©todo detect_extended() com confian√ßa prob.
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ allow_list.py         ‚Üê Lista de termos seguros (375 termos)
‚îÇ   ‚îÇ                           - √ìrg√£os do GDF (SEEDF, SESDF, DETRAN, etc)
‚îÇ   ‚îÇ                           - Regi√µes administrativas de Bras√≠lia
‚îÇ   ‚îÇ                           - Endere√ßos administrativos (SQS, SQN, etc)
‚îÇ   ‚îÇ                           - Confian√ßa base por tipo de PII
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ confidence/           ‚Üê NOVO: M√≥dulo de confian√ßa probabil√≠stica
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py       ‚Üê Exports do m√≥dulo
‚îÇ       ‚îú‚îÄ‚îÄ types.py          ‚Üê PIIEntity, DocumentConfidence, SourceDetection
‚îÇ       ‚îú‚îÄ‚îÄ config.py         ‚Üê FN_RATES, FP_RATES, PESOS_LGPD, thresholds
‚îÇ       ‚îú‚îÄ‚îÄ validators.py     ‚Üê Valida√ß√£o DV (CPF, CNPJ, PIS, CNS, etc)
‚îÇ       ‚îú‚îÄ‚îÄ calibration.py    ‚Üê IsotonicCalibrator, CalibratorRegistry
‚îÇ       ‚îú‚îÄ‚îÄ combiners.py      ‚Üê ProbabilityCombiner, EntityAggregator
‚îÇ       ‚îî‚îÄ‚îÄ calculator.py     ‚Üê PIIConfidenceCalculator (orquestrador)
‚îÇ
‚îú‚îÄ‚îÄ main_cli.py               ‚Üê CLI para processamento em lote
‚îÇ                               - Entrada: CSV/XLSX com coluna "Texto Mascarado"
‚îÇ                               - Sa√≠da: JSON + CSV + XLSX com cores
‚îÇ
‚îú‚îÄ‚îÄ benchmark.py              ‚Üê üèÜ Benchmark LGPD: 303 casos de teste
‚îÇ                               - F1-Score = 1.0000 (100% P/R)
‚îÇ                               - Casos seguros (n√£o PII)
‚îÇ                               - PIIs cl√°ssicos (CPF, Email, Telefone)
‚îÇ                               - Edge cases de Bras√≠lia/GDF
‚îÇ                               - Imunidade funcional
‚îÇ
‚îú‚îÄ‚îÄ test_confianca.py         ‚Üê Testes do sistema de confian√ßa
‚îÇ                               - Valida√ß√£o de d√≠gitos verificadores
‚îÇ                               - Calibra√ß√£o isot√¥nica
‚îÇ                               - Combina√ß√£o log-odds
‚îÇ
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ input/                ‚Üê Arquivos para processar em lote
    ‚îî‚îÄ‚îÄ output/               ‚Üê Relat√≥rios gerados
        ‚îú‚îÄ‚îÄ resultado.json    ‚Üê Dados estruturados
        ‚îú‚îÄ‚îÄ resultado.csv     ‚Üê Planilha simples
        ‚îî‚îÄ‚îÄ resultado.xlsx    ‚Üê Excel com formata√ß√£o de cores
```

---

## 1Ô∏è‚É£ INSTRU√á√ïES DE INSTALA√á√ÉO E DEPEND√äNCIAS

### 1.1 Pr√©-requisitos

| Software | Vers√£o M√≠nima | Verificar | Como Instalar |
|----------|---------------|-----------|---------------|
| **Python** | 3.10+ | `python --version` | [python.org](https://www.python.org/downloads/) |
| **pip** | 23.0+ | `pip --version` | Inclu√≠do com Python |
| **Git** | 2.0+ | `git --version` | [git-scm.com](https://git-scm.com/) |

**Requisitos de Sistema:**
- **RAM:** M√≠nimo 4GB (recomendado 8GB para modelos NLP)
- **Disco:** ~3GB (modelos spaCy + BERT)
- **Internet:** Necess√°ria para download inicial dos modelos

### 1.2 Arquivo de Depend√™ncias: `requirements.txt`

```txt
# ===========================================
# Participa DF - Backend Requirements
# Python 3.10 (compat√≠vel com spaCy 3.8)
# ===========================================

# === Framework Web ===
fastapi==0.110.0              # API REST ass√≠ncrona
uvicorn==0.27.1               # Servidor ASGI de alta performance
python-multipart==0.0.9       # Upload de arquivos

# === Processamento de Dados ===
pandas==2.2.1                 # Manipula√ß√£o de DataFrames
openpyxl==3.1.2               # Leitura/escrita de Excel

# === NLP Core ===
spacy==3.8.0                  # NLP para portugu√™s (pt_core_news_lg)
text-unidecode==1.3           # Normaliza√ß√£o de strings

# === Transformers + PyTorch (CPU) ===
transformers==4.41.2          # BERT NER multil√≠ngue
sentencepiece==0.1.99         # Tokeniza√ß√£o
accelerate>=0.21.0            # Otimiza√ß√£o de infer√™ncia

# NOTA: PyTorch instalado separadamente no Dockerfile
# pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu
```

### 1.3 Instala√ß√£o Passo a Passo

```bash
# 1. Clone o reposit√≥rio (se ainda n√£o fez)
git clone https://github.com/marinhothiago/desafio-participa-df.git
cd desafio-participa-df/backend

# 2. Crie ambiente virtual Python
python -m venv venv

# 3. Ative o ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Instale PyTorch CPU (ANTES das outras depend√™ncias)
pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu

# 5. Instale todas as depend√™ncias
pip install -r requirements.txt

# 6. Baixe o modelo spaCy para portugu√™s (OBRIGAT√ìRIO)
python -m spacy download pt_core_news_lg

# 7. (Opcional) Verifique a instala√ß√£o
python -c "import spacy; nlp = spacy.load('pt_core_news_lg'); print('‚úÖ spaCy OK')"
python -c "from transformers import pipeline; print('‚úÖ Transformers OK')"
```

**Tempo estimado:** 5-10 minutos (primeira instala√ß√£o)

---

## 2Ô∏è‚É£ INSTRU√á√ïES DE EXECU√á√ÉO

### 2.1 Servidor API (FastAPI)

```bash
# Certifique-se de estar na pasta backend/
cd backend

# Ative o ambiente virtual (se n√£o estiver ativo)
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Inicie o servidor
uvicorn api.main:app --host 0.0.0.0 --port 7860 --reload
```

**Sa√≠da esperada:**
```
INFO:     üèÜ [v9.4.3] VERS√ÉO HACKATHON - ENSEMBLE 5 FONTES + CONFIAN√áA PROBABIL√çSTICA
INFO:     ‚úÖ spaCy pt_core_news_lg carregado
INFO:     ‚úÖ BERT Davlan NER multil√≠ngue carregado (PER, ORG, LOC, DATE)
INFO:     ‚úÖ NuNER pt-BR carregado (especializado em portugu√™s)
INFO:     Uvicorn running on http://0.0.0.0:7860 (Press CTRL+C to quit)
```

**Endpoints dispon√≠veis:**
| Endpoint | M√©todo | Descri√ß√£o |
|----------|--------|-----------|
| `/analyze` | POST | Analisa texto para detec√ß√£o de PII |
| `/health` | GET | Verifica status da API |
| `/docs` | GET | Documenta√ß√£o Swagger interativa |
| `/redoc` | GET | Documenta√ß√£o ReDoc |

### 2.2 CLI (Processamento em Lote)

```bash
# Ative o ambiente virtual
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate

# Execute o processamento
python main_cli.py --input data/input/manifestacoes.xlsx --output data/output/resultado
```

**Argumentos:**
| Argumento | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-----------|------|-------------|-----------|
| `--input` | string | ‚úÖ | Caminho do arquivo CSV ou XLSX |
| `--output` | string | ‚úÖ | Nome base dos arquivos de sa√≠da |

**Arquivos gerados (todos com mesma estrutura de colunas):**
| Arquivo | Formato | Uso |
|---------|---------|-----|
| `resultado.json` | JSON | Integra√ß√£o com sistemas, APIs |
| `resultado.csv` | CSV UTF-8 | Importa√ß√£o em outras ferramentas |
| `resultado.xlsx` | Excel | An√°lise visual com cores por risco |

**Colunas de sa√≠da (ordem padronizada):**
1. `ID` - Identificador original do registro
2. `Texto Mascarado` - Texto analisado
3. `Classifica√ß√£o` - ‚úÖ P√öBLICO ou ‚ùå N√ÉO P√öBLICO
4. `Confian√ßa` - Percentual de certeza (ex: 98.5%)
5. `N√≠vel de Risco` - SEGURO, BAIXO, MODERADO, ALTO, CR√çTICO
6. `Identificadores` - Lista de PIIs detectados

### 2.3 Execu√ß√£o com Docker

```bash
# Na pasta backend/
docker build -t participa-df-backend .

# Execute o container
docker run -p 7860:7860 participa-df-backend
```

**Ou usando docker-compose (da raiz do projeto):**
```bash
cd ..  # volta para a raiz
docker-compose up backend
```

---

## üìä Formato de Dados

### Endpoints Dispon√≠veis

| Endpoint | M√©todo | Descri√ß√£o |
|----------|--------|-----------|
| `/analyze` | POST | Analisa texto para detec√ß√£o de PII |
| `/health` | GET | Verifica status da API |
| `/stats` | GET | Retorna estat√≠sticas globais de uso |
| `/stats/visit` | POST | Registra uma visita ao site |

### Estat√≠sticas Globais (v9.4)

**GET /stats** - Retorna contadores globais:
```json
{
  "site_visits": 1234,
  "classification_requests": 5678,
  "last_updated": "2026-01-16T10:30:00"
}
```

**POST /stats/visit** - Registra visita (chamado 1x por sess√£o do frontend):
```json
{
  "site_visits": 1235,
  "classification_requests": 5678,
  "last_updated": "2026-01-16T10:31:00"
}
```

> **Nota:** O contador `classification_requests` √© incrementado automaticamente a cada chamada ao `/analyze`.

### Entrada (POST /analyze)

```json
{
  "text": "Meu CPF √© 123.456.789-09 e preciso de ajuda urgente.",
  "id": "manifestacao_001"
}
```

| Campo | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-------|------|-------------|-----------|
| `text` | string | ‚úÖ Sim | Texto a ser analisado (m√°x 10.000 caracteres) |
| `id` | string | ‚ùå N√£o | ID para rastreabilidade (preservado na sa√≠da) |

### Sa√≠da

```json
{
  "id": "manifestacao_001",
  "classificacao": "N√ÉO P√öBLICO",
  "risco": "CR√çTICO",
  "confianca": 0.98,
  "detalhes": [
    {
      "tipo": "CPF",
      "valor": "123.456.789-09",
      "confianca": 1.0
    }
  ]
}
```

| Campo | Tipo | Valores | Descri√ß√£o |
|-------|------|---------|-----------|
| `id` | string | qualquer | ID preservado da entrada |
| `classificacao` | string | "P√öBLICO", "N√ÉO P√öBLICO" | Se pode publicar |
| `risco` | string | SEGURO, BAIXO, MODERADO, ALTO, CR√çTICO | Severidade |
| `confianca` | float | 0.0 - 1.0 | Certeza do modelo (normalizado) |
| `detalhes` | array | objetos | Lista de PIIs encontrados |

### Formato de Arquivo para CLI (CSV/XLSX)

O arquivo deve conter uma coluna `Texto Mascarado` (ou `text`):

```csv
ID,Texto Mascarado
man_001,"Solicito informa√ß√µes sobre minha situa√ß√£o cadastral."
man_002,"Meu CPF √© 529.982.247-25 e telefone (61) 98765-4321."
man_003,"Reclama√ß√£o contra o servidor Jo√£o Silva do DETRAN."
```

**Sa√≠da do CLI (mesma estrutura nos 3 formatos):**

```csv
ID,Texto Mascarado,Classifica√ß√£o,Confian√ßa,N√≠vel de Risco,Identificadores
man_001,"Solicito informa√ß√µes...","‚úÖ P√öBLICO","100.0%","SEGURO","[]"
man_002,"Meu CPF √© 529.982.247-25...","‚ùå N√ÉO P√öBLICO","98.0%","CR√çTICO","['CPF: 529.982.247-25', 'TELEFONE: (61) 98765-4321']"
```

```json
[
  {
    "id": "man_001",
    "texto_mascarado": "Solicito informa√ß√µes...",
    "classificacao": "‚úÖ P√öBLICO",
    "confianca": "100.0%",
    "nivel_risco": "SEGURO",
    "identificadores": "[]"
  },
  {
    "id": "man_002",
    "texto_mascarado": "Meu CPF √© 529.982.247-25...",
    "classificacao": "‚ùå N√ÉO P√öBLICO",
    "confianca": "98.0%",
    "nivel_risco": "CR√çTICO",
    "identificadores": "['CPF: 529.982.247-25', 'TELEFONE: (61) 98765-4321']"
  }
]
```

---

## üß† Arquitetura do Motor de Detec√ß√£o (v9.4.3)

### Pipeline de Processamento

```
Texto de Entrada
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CAMADA 1: REGEX                           ‚îÇ
‚îÇ  ‚Ä¢ CPF (com valida√ß√£o de d√≠gito verificador)                 ‚îÇ
‚îÇ  ‚Ä¢ CNPJ, PIS, CNS, T√≠tulo de Eleitor (valida√ß√£o DV)         ‚îÇ
‚îÇ  ‚Ä¢ RG, CNH, Passaporte, CTPS, Certid√µes                     ‚îÇ
‚îÇ  ‚Ä¢ Email pessoal (exclui .gov.br, .org.br, .edu.br)         ‚îÇ
‚îÇ  ‚Ä¢ Telefone (fixo, celular, DDI)                             ‚îÇ
‚îÇ  ‚Ä¢ Endere√ßo residencial, CEP                                 ‚îÇ
‚îÇ  ‚Ä¢ Dados banc√°rios, PIX, Cart√£o de cr√©dito                   ‚îÇ
‚îÇ  ‚Ä¢ Placa de ve√≠culo (Mercosul e antiga)                      ‚îÇ
‚îÇ  ‚Ä¢ Data de nascimento, IP Address                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA 2: BERT NER (prim√°rio)                   ‚îÇ
‚îÇ  Modelo: Davlan/bert-base-multilingual-cased-ner-hrl        ‚îÇ
‚îÇ  ‚Ä¢ Detector prim√°rio de nomes pessoais (PER)                 ‚îÇ
‚îÇ  ‚Ä¢ Threshold de confian√ßa: 0.75                              ‚îÇ
‚îÇ  ‚Ä¢ Filtros: nome + sobrenome, n√£o em blocklist               ‚îÇ
‚îÇ  ‚Ä¢ Verifica imunidade funcional antes de marcar              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            CAMADA 3: spaCy (complementar)                    ‚îÇ
‚îÇ  Modelo: pt_core_news_lg (portugu√™s)                         ‚îÇ
‚îÇ  ‚Ä¢ Captura nomes que o BERT n√£o detectou                     ‚îÇ
‚îÇ  ‚Ä¢ Roda em paralelo, n√£o √© fallback                          ‚îÇ
‚îÇ  ‚Ä¢ Evita duplicatas: s√≥ adiciona se BERT n√£o encontrou       ‚îÇ
‚îÇ  ‚Ä¢ Mesmos filtros de qualidade                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA 4: REGRAS DE NEG√ìCIO                     ‚îÇ
‚îÇ  ‚Ä¢ Gatilhos de contato: "falar com", "ligar para"           ‚îÇ
‚îÇ    ‚Üí Nome ap√≥s gatilho = SEMPRE PII                          ‚îÇ
‚îÇ  ‚Ä¢ Imunidade funcional: "Dr. Jo√£o da Secretaria"             ‚îÇ
‚îÇ    ‚Üí Servidor em contexto funcional = N√ÉO PII                ‚îÇ
‚îÇ  ‚Ä¢ Contexto Bras√≠lia: SQS, SQN, Eixo = endere√ßo p√∫blico     ‚îÇ
‚îÇ  ‚Ä¢ Blocklist: sauda√ß√µes, termos administrativos              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ENSEMBLE OR + DEDUPLICA√á√ÉO                  ‚îÇ
‚îÇ  ‚Ä¢ Combina achados de todas as camadas                       ‚îÇ
‚îÇ  ‚Ä¢ Remove duplicatas priorizando maior peso                  ‚îÇ
‚îÇ  ‚Ä¢ Calcula risco m√°ximo e confian√ßa composta                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
   Resultado Final
   (classificacao, risco, confianca, detalhes)
```

### Sistema de Confian√ßa Composta

A confian√ßa de cada PII detectado √© calculada dinamicamente:

```
confian√ßa_final = min(1.0, confian√ßa_base √ó fator_contexto)
```

#### Confian√ßa Base por M√©todo

| M√©todo | Tipos | Base | Justificativa |
|--------|-------|------|---------------|
| **Regex + DV** | CPF, PIS, CNS, CNH, T√≠tulo Eleitor, CTPS | 0.98 | Valida√ß√£o matem√°tica |
| **Regex + Luhn** | Cart√£o Cr√©dito | 0.95 | Algoritmo v√°lido |
| **Regex estrutural** | Email, Telefone, Placa, PIX | 0.85-0.95 | Padr√£o claro |
| **Regex + contexto** | CEP, Data Nascimento | 0.70-0.75 | Depende de contexto |
| **BERT NER** | Nomes | score do modelo | Retorna 0.75-0.99 |
| **spaCy NER** | Nomes | 0.70 | Modelo complementar |
| **Gatilho** | Nomes ap√≥s "falar com" | 0.85 | Padr√£o lingu√≠stico |

#### Fatores de Contexto

| Fator | Ajuste | Exemplo |
|-------|--------|---------|
| Possessivo | +15% | "**Meu** CPF √©..." |
| Label expl√≠cito | +10% | "**CPF:** 529..." |
| Verbo declarativo | +5% | "CPF **√©** 529..." |
| Gatilho de contato | +10% | "**falar com** Jo√£o" |
| Contexto de teste | -25% | "**exemplo**: 000..." |
| Declarado fict√≠cio | -30% | "CPF **fict√≠cio**" |
| Nega√ß√£o | -20% | "**n√£o √©** meu CPF" |
| Institucional | -10% | "CPF **da empresa**" |

#### Exemplos de C√°lculo

```python
# Exemplo 1: CPF com possessivo e label
texto = "Meu CPF: 529.982.247-25"
base = 0.98  # DV v√°lido
fator = 1.0 + 0.15 (possessivo) + 0.10 (label) = 1.25
confianca = min(1.0, 0.98 * 1.25) = 1.0  # Capped

# Exemplo 2: CPF em contexto de exemplo
texto = "exemplo de CPF: 529.982.247-25"
base = 0.98
fator = 1.0 - 0.25 (exemplo) = 0.75
confianca = 0.98 * 0.75 = 0.74  # Baixa, pode ser filtrado

# Exemplo 3: Nome detectado por BERT com gatilho
texto = "falar com Jo√£o Silva"
base = 0.87  # Score do BERT
fator = 1.0 + 0.10 (gatilho) = 1.10
confianca = min(1.0, 0.87 * 1.10) = 0.96
```

### Tipos de PII Detectados

| Categoria | Tipos | Peso | Valida√ß√£o |
|-----------|-------|------|-----------|
| **Documentos** | CPF, RG, CNH, Passaporte, PIS, CNS, CNPJ (MEI), T√≠tulo Eleitor, CTPS, Certid√µes | 5 (Cr√≠tico) | D√≠gito Verificador |
| **Contato** | Email pessoal, Telefone, Celular | 4 (Alto) | Regex + exclus√£o institucional |
| **Localiza√ß√£o** | Endere√ßo residencial, CEP | 4 (Alto) | Contexto "moro", "resido" |
| **Financeiro** | Conta banc√°ria, PIX, Cart√£o de cr√©dito | 4 (Alto) | Padr√µes estruturados |
| **Identifica√ß√£o** | Nome completo, Nome em contexto | 3-4 | BERT NER + regras |
| **Outros** | Placa de ve√≠culo, Data nascimento, IP | 3 (Moderado) | Regex |

### Imunidade Funcional (LAI)

Servidores p√∫blicos em exerc√≠cio de fun√ß√£o **N√ÉO s√£o PII**:
- ‚úÖ "A Dra. Maria da Secretaria de Sa√∫de informou que..."
- ‚úÖ "O servidor Jos√© Santos do DETRAN atendeu a demanda"
- ‚úÖ "Funcion√°rio do m√™s: Pedro Oliveira"

**Gatilhos que ANULAM imunidade:**
- ‚ùå "Preciso falar com o Jo√£o Silva sobre isso"
- ‚ùå "Ligar para a Dra. Maria no celular"
- ‚ùå "Endere√ßo da Maria: Rua das Flores, 123"

---

## üß™ Testes e Benchmark

```bash
# Na pasta backend/, com ambiente virtual ativo

# Execute o benchmark LGPD (303 casos, F1=1.0)
python benchmark.py

# Execute os testes de confian√ßa
python test_confianca.py
```

**Benchmark LGPD (303 casos - F1-Score = 1.0000):**

| Grupo | Quantidade | Esperado | Descri√ß√£o |
|-------|------------|----------|-----------|
| Administrativo | 50+ | P√öBLICO | Textos burocr√°ticos sem PII |
| PII Cl√°ssico | 80+ | N√ÉO P√öBLICO | CPF, Email, Telefone, RG, etc |
| Nomes | 40+ | Variado | Nomes com contexto funcional vs pessoal |
| Edge Cases | 50+ | Variado | Situa√ß√µes amb√≠guas, Bras√≠lia/GDF |
| Imunidade | 30+ | P√öBLICO | Servidores em exerc√≠cio |
| Gatilhos | 25+ | N√ÉO P√öBLICO | "falar com", "ligar para" |
| Documentos DV | 25+ | N√ÉO P√öBLICO | CPF, CNPJ, PIS, CNS com valida√ß√£o |

---

## üê≥ Dockerfile

```dockerfile
# Python 3.10 slim para menor tamanho
FROM python:3.10-slim

# Vari√°veis de ambiente
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Depend√™ncias do sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential curl && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Instala PyTorch CPU
RUN pip install --no-cache-dir torch==2.1.0+cpu \
    --index-url https://download.pytorch.org/whl/cpu

# Instala depend√™ncias Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Baixa modelo spaCy
RUN pip install --no-cache-dir \
    https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.8.0/pt_core_news_lg-3.8.0-py3-none-any.whl

# Pr√©-download BERT NER
RUN python -c "from transformers import pipeline; \
    pipeline('ner', model='Davlan/bert-base-multilingual-cased-ner-hrl')"

# Copia c√≥digo
COPY . .

# Porta HuggingFace Spaces
EXPOSE 7860

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:7860/health || exit 1

# Comando de inicializa√ß√£o
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "7860"]
```

---

## üìö C√≥digo Fonte Comentado

### Exemplo: Motor de Detec√ß√£o (`src/detector.py`)

```python
class PIIDetector:
    """Detector h√≠brido de PII com ensemble de alta recall.
    
    Estrat√©gia: Ensemble OR - qualquer detector positivo classifica como PII.
    Isso maximiza recall (n√£o deixar escapar nenhum PII) √†s custas de alguns
    falsos positivos, que √© a estrat√©gia correta para LAI/LGPD.
    """

    def __init__(self, usar_gpu: bool = True) -> None:
        """Inicializa o detector com todos os modelos NLP.
        
        Args:
            usar_gpu: Se True, usa CUDA quando dispon√≠vel
        """
        logger.info("üèÜ [v9.2] F1-Score = 1.0000 - Benchmark LGPD")
        
        self.validador = ValidadorDocumentos()
        self._inicializar_modelos(usar_gpu)
        self._inicializar_vocabularios()
        self._compilar_patterns()

    def detect(self, text: str) -> Tuple[bool, List[Dict], str, float]:
        """Detecta PII no texto usando ensemble de alta recall.
        
        Pipeline:
        1. Regex com valida√ß√£o de DV (documentos)
        2. Extra√ß√£o de nomes ap√≥s gatilhos de contato
        3. NER com BERT + spaCy (nomes e entidades)
        4. Deduplica√ß√£o com prioridade por peso
        
        Args:
            text: Texto a ser analisado
            
        Returns:
            Tuple com:
            - is_pii (bool): True se cont√©m PII
            - findings (List[Dict]): PIIs encontrados
            - nivel_risco (str): CRITICO, ALTO, MODERADO, BAIXO, SEGURO
            - confianca (float): Score 0-1 normalizado
        """
```

### Exemplo: API FastAPI (`api/main.py`)

```python
@app.post("/analyze")
async def analyze(data: Dict[str, Optional[str]]) -> Dict:
    """Analisa texto para detec√ß√£o de PII com contexto Bras√≠lia/GDF.
    
    Realiza detec√ß√£o h√≠brida usando:
    - Regex: Padr√µes estruturados (CPF, Email, Telefone, RG, CNH)
    - NLP: Reconhecimento de entidades com spaCy + BERT
    - Regras de Neg√≥cio: Contexto de Bras√≠lia, imunidade funcional (LAI)
    
    Args:
        data: Dict com "text" (obrigat√≥rio) e "id" (opcional)
    
    Returns:
        Dict com classificacao, risco, confianca e detalhes
    """
```

---

## üîó Integra√ß√£o com Frontend

O frontend React se conecta automaticamente ao backend:

1. **Detec√ß√£o autom√°tica:** Tenta `localhost:7860` primeiro (2s timeout)
2. **Fallback produ√ß√£o:** Se local n√£o dispon√≠vel, usa HuggingFace Spaces
3. **Retry autom√°tico:** 1 retry com delay de 3s para cold start

```typescript
// frontend/src/lib/api.ts
const PRODUCTION_API_URL = 'https://marinhothiago-desafio-participa-df.hf.space';
const LOCAL_API_URL = 'http://localhost:7860';
```

---

## üéØ Sistema de Confian√ßa Probabil√≠stica (v9.4)

O backend inclui um sistema sofisticado de c√°lculo de confian√ßa baseado em pr√°ticas de produ√ß√£o de grandes empresas (Google, Microsoft, Meta) e bancos brasileiros.

### Arquitetura do M√≥dulo

```
backend/src/confidence/
‚îú‚îÄ‚îÄ __init__.py        # Exports do m√≥dulo
‚îú‚îÄ‚îÄ types.py           # Dataclasses (PIIEntity, DocumentConfidence)
‚îú‚îÄ‚îÄ config.py          # Taxas FN/FP, pesos LGPD, thresholds
‚îú‚îÄ‚îÄ validators.py      # Valida√ß√£o de d√≠gitos verificadores
‚îú‚îÄ‚îÄ calibration.py     # Calibra√ß√£o isot√¥nica de scores
‚îú‚îÄ‚îÄ combiners.py       # Combina√ß√£o via Log-Odds (Naive Bayes)
‚îî‚îÄ‚îÄ calculator.py      # Orquestrador principal
```

### Componentes Principais

#### 1. Calibra√ß√£o de Scores (Isotonic Regression)

Modelos neurais como BERT s√£o frequentemente **overconfident** - retornam scores altos mesmo quando erram. A calibra√ß√£o isot√¥nica corrige isso:

```python
# Score bruto 0.95 -> Score calibrado ~0.85
# Score bruto 0.99 -> Score calibrado ~0.90
```

#### 2. Combina√ß√£o via Log-Odds (Naive Bayes)

Quando m√∫ltiplas fontes detectam a mesma entidade, combinamos via log-odds:

$$
\text{logit} = \log\frac{p_{\text{prior}}}{1 - p_{\text{prior}}} + \sum_i \log\frac{p_i}{FP_i}
$$

$$
\text{confidence} = \frac{e^{\text{logit}}}{1 + e^{\text{logit}}}
$$

#### 3. Taxas de Erro por Fonte

```python
# False Negative Rates (quanto cada fonte PERDE)
FN_RATES = {
    "bert_ner": 0.008,      # BERT perde 0.8%
    "spacy": 0.015,         # spaCy perde 1.5%
    "regex": 0.003,         # Regex perde 0.3%
    "dv_validation": 0.0001 # DV quase perfeito
}

# False Positive Rates (alarmes falsos)
FP_RATES = {
    "bert_ner": 0.02,       # 2% de FP
    "spacy": 0.03,          # 3% de FP
    "regex": 0.0002,        # Muito preciso
    "dv_validation": 0.00001 # Quase imposs√≠vel ser FP
}
```

#### 4. M√©tricas de Documento

- **`confidence_no_pii`**: P(n√£o existe PII) quando nada detectado
- **`confidence_all_found`**: P(encontramos todo PII) quando tem detec√ß√µes
- **`confidence_min_entity`**: Menor confian√ßa entre entidades (elo mais fraco)

### Novo Endpoint Extendido

```python
# M√©todo detect_extended() retorna estrutura completa
resultado = detector.detect_extended(texto)

# Estrutura de resposta:
{
    "has_pii": True,
    "classificacao": "N√ÉO P√öBLICO",
    "risco": "CR√çTICO",
    "confidence": {
        "no_pii": 0.0,
        "all_found": 0.9999,
        "min_entity": 0.9850
    },
    "sources_used": ["bert_ner", "spacy", "regex"],
    "entities": [
        {
            "tipo": "CPF",
            "valor": "529.982.247-25",
            "confianca": 0.9999,
            "confidence_level": "very_high",
            "sources": ["regex", "dv_validation"],
            "dv_valid": True
        }
    ],
    "total_entities": 1
}
```

### Valida√ß√£o de D√≠gitos Verificadores

O m√≥dulo valida automaticamente documentos brasileiros:

| Documento | Algoritmo | Confian√ßa se V√°lido |
|-----------|-----------|---------------------|
| CPF | M√≥dulo 11 | 0.9999 |
| CNPJ | M√≥dulo 11 com pesos | 0.9999 |
| PIS/NIT | M√≥dulo 11 com pesos | 0.9999 |
| CNS | Soma ponderada | 0.9999 |
| T√≠tulo Eleitor | DVs espec√≠ficos por UF | 0.9999 |
| Cart√£o Cr√©dito | Luhn | 0.9999 |

### Backward Compatibility

O m√©todo `detect()` original continua funcionando:

```python
# API antiga (mantida)
is_pii, findings, risco, conf = detector.detect(texto)

# API nova (recomendada)
resultado = detector.detect_extended(texto)
```

---

## üìÑ Licen√ßa

Desenvolvido para o **Hackathon Participa DF 2025** em conformidade com:
- **LGPD** - Lei Geral de Prote√ß√£o de Dados (Lei n¬∫ 13.709/2018)
- **LAI** - Lei de Acesso √† Informa√ß√£o (Lei n¬∫ 12.527/2011)

---

## üöÄ Deploy no Hugging Face Spaces: Quais arquivos v√£o para produ√ß√£o?

Para garantir builds r√°pidos, seguros e reprodut√≠veis no Hugging Face Spaces (ou Docker em produ√ß√£o), **apenas os arquivos essenciais devem ser enviados para o contexto de build**:


### Checklist de Deploy (Docker/Hugging Face)

**Inclua no build:**
- `src/` (c√≥digo-fonte principal)
- `api/` (endpoints FastAPI)
- `requirements.txt` (depend√™ncias)
- `Dockerfile` (build)
- `data/input/AMOSTRA_e-SIC.xlsx` (amostra oficial, permitida no build)

**Ignore tudo que for apenas para desenvolvimento local:**
- `scripts/` (automatiza√ß√µes, limpeza, etc)
- arquivos de teste, notebooks, caches, dados sens√≠veis n√£o autorizados

**Observa√ß√£o:**
- A amostra `AMOSTRA_e-SIC.xlsx` pode ir para produ√ß√£o (Docker/HF) conforme decis√£o do projeto/hackathon.
- O diret√≥rio `scripts/` √© exclusivo para automa√ß√µes e limpeza local, nunca vai para produ√ß√£o.

**Dica:** O arquivo `.dockerignore` j√° est√° configurado para ignorar scripts/ e artefatos de dev. Se for subir manualmente para o Hugging Face, envie s√≥ os arquivos essenciais e a amostra permitida!

---
