
---
title: Desafio Participa DF
emoji: üöÄ
colorFrom: indigo
colorTo: blue
sdk: docker
app_file: app.py
pinned: false
---


## üõ†Ô∏è Troubleshooting & Edge Cases (Presidio/ONNX)

### Erros comuns e solu√ß√µes r√°pidas

- **ImportError: 'optimum.onnxruntime' could not be resolved**
  - Solu√ß√£o: Execute `pip install optimum[onnx] onnxruntime` no seu ambiente virtual.
  - Dica: Sempre ative o venv antes de instalar (`source venv/bin/activate` ou `venv\Scripts\activate`).

- **Presidio n√£o encontra Recognizers customizados**
  - Solu√ß√£o: Verifique se o m√©todo `_compilar_patterns` foi chamado no construtor do `PIIDetector`.
  - Dica: Veja logs de inicializa√ß√£o para "Recognizer registrado".

- **ONNX n√£o √© usado mesmo com modelo exportado**
  - Solu√ß√£o: Confirme se o arquivo `backend/models/bert_ner_onnx/model.onnx` existe e est√° acess√≠vel.
  - Dica: Veja logs para "ONNX NER carregado". Se falhar, o fallback para transformers √© autom√°tico.

- **Erro de importa√ß√£o de allow_list ou gazetteer**
  - Solu√ß√£o: Confirme se os arquivos/m√≥dulos est√£o no diret√≥rio correto (`src/`). Use imports relativos no backend.

- **Problemas de performance (CPU alto, resposta lenta)**
  - Dica: ONNX acelera BERT NER em at√© 5x. Se n√£o estiver usando, revise depend√™ncias e modelo exportado.

- **Reconhecedores customizados n√£o detectam entidades**
  - Solu√ß√£o: Adicione prints/logs no m√©todo `analyze` do seu Recognizer para depurar entradas e sa√≠das.
  - Dica: Use `logger.warning` para mensagens vis√≠veis em produ√ß√£o.

- **Logs n√£o aparecem**
  - Solu√ß√£o: Certifique-se que o logger est√° configurado no in√≠cio do projeto (`logging.basicConfig(level=logging.INFO)`).

### Edge Cases e dicas avan√ßadas

- O fallback para pipelines transformers/spaCy/NuNER √© autom√°tico se ONNX falhar.
- Todos os Recognizers customizados podem ser removidos/adicionados em tempo de execu√ß√£o via registry do Presidio.
- Para debugging profundo, ative logs DEBUG no in√≠cio do app:
  ```python
  import logging
  logging.basicConfig(level=logging.DEBUG)
  ```
- Para auditar decis√µes, cada achado traz o campo `explanation` e `source`.
- Para expandir entidades, basta registrar um novo Recognizer (n√£o precisa alterar o core).

### Links √∫teis
- [Presidio Analyzer Docs](https://microsoft.github.io/presidio/analyzer/)
- [Optimum ONNX Export](https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model)
- [Exemplo de Recognizer customizado](https://microsoft.github.io/presidio/analyzer/development/adding_recognizers/)

---
---
title: Participa DF - Detector Inteligente de Dados Pessoais
emoji: üõ°Ô∏è
colorFrom: blue
colorTo: green
sdk: docker
app_file: api/main.py
pinned: false
---

## üöÄ MELHORIAS E FUNCIONALIDADES AVAN√áADAS (2025-2026)

- üèõÔ∏è **Gazetteer institucional GDF:** Filtro de falsos positivos para nomes de √≥rg√£os, escolas, hospitais e aliases do DF, edit√°vel via `src/gazetteer_gdf.json`. Garante m√°xima precis√£o em contexto Bras√≠lia/DF.
- üß† **Sistema de confian√ßa probabil√≠stica:** Calibra√ß√£o isot√¥nica + log-odds, thresholds din√¢micos por tipo, fatores de contexto, explica√ß√£o detalhada abaixo.
- ‚ö° **P√≥s-processamento de spans:** Normaliza√ß√£o, merge/split, deduplica√ß√£o de entidades para m√°xima precis√£o, via `pos_processar_spans.py`.
- üèÜ **Benchmark LGPD/LAI:** 318+ casos reais, F1-score 0.9763, todos FPs/FNs conhecidos e documentados.
- üîí **Seguran√ßa do token Hugging Face:** Uso obrigat√≥rio de `.env` (n√£o versionado), carregamento autom√°tico em todos os entrypoints, nunca exposto em c√≥digo ou log.
- üßπ **Limpeza e organiza√ß√£o:** `.gitignore` e `.dockerignore` revisados, scripts de limpeza, deploy seguro, documenta√ß√£o atualizada.
- üê≥ **Deploy profissional:** Docker Compose, Hugging Face Spaces, checklist de produ√ß√£o.
- üõ†Ô∏è **Otimizador de ensemble:** `optimize_ensemble.py` para grid search de pesos do ensemble, reuso de detector, e valida√ß√£o autom√°tica.

---
## üÜï Estrat√©gias de Merge de Spans (Presets)

A partir da vers√£o 9.4.3, o endpoint `/analyze` permite escolher a estrat√©gia de merge de spans (entidades sobrepostas) via par√¢metro `merge_preset`:

- `recall`: Mant√©m todos os spans sobrepostos (maximiza recall, √∫til para auditoria).
- `precision`: Mant√©m apenas o span com maior score/confian√ßa (maximiza precis√£o, √∫til para produ√ß√£o).
- `f1`: Mant√©m o span mais longo por sobreposi√ß√£o (equil√≠brio entre recall e precis√£o, padr√£o).
- `custom`: Permite l√≥gica customizada (exemplo: priorizar fonte espec√≠fica ou l√≥gica pr√≥pria).

### Como usar na API

```http
POST /analyze?merge_preset=recall
Content-Type: application/json
{
  "text": "Meu CPF √© 123.456.789-09 e meu telefone √© 99999-8888"
}
```

- `merge_preset` pode ser: `recall`, `precision`, `f1`, `custom` (default: `f1`)
- O resultado em `detalhes` refletir√° a estrat√©gia escolhida.

### Exemplos de uso via curl

```bash
# Maximizar recall (todos spans):

# Maximizar precis√£o (apenas maior score):
curl -X POST "http://localhost:8000/analyze?merge_preset=precision" -H "Content-Type: application/json" -d '{"text": "Meu CPF √© 123.456.789-09"}'

# Customizado:
```

### Observa√ß√µes
- O merge s√≥ √© aplicado se as entidades retornadas tiverem `start` e `end` (posi√ß√£o no texto).
- Para uso avan√ßado, consulte `src/confidence/combiners.py` e ajuste a fun√ß√£o `merge_spans_custom`.
- O preset `custom` pode ser expandido para l√≥gica pr√≥pria no backend.

---
# üìö COMO USAR AS NOVAS FUNCIONALIDADES
### Gazetteer GDF
- Edite `src/gazetteer_gdf.json` para adicionar √≥rg√£os, escolas, hospitais, programas ou aliases. O detector ignora entidades que batem com o gazetteer, reduzindo FPs em contexto institucional.

- Execute `python optimize_ensemble.py` para buscar os melhores pesos do ensemble. O script reusa o detector e valida o F1-score automaticamente.
### Seguran√ßa do Token Hugging Face
- Crie um `.env` (N√ÉO versionado) com `HF_TOKEN=seu_token`. O backend carrega automaticamente. Nunca exponha o token em c√≥digo ou log.

- [x] `.env` nunca versionado
- [x] Modelos baixados no build do Docker
- [x] Scripts de limpeza n√£o v√£o para produ√ß√£o
- [x] Testes e benchmark executados antes do deploy
```bash
python main_cli.py --input data/input/manifestacoes.xlsx --output data/output/resultado

# Rodar benchmark completo

python pos_processar_spans.py --input data/output/resultado.json --output data/output/resultado_pos.json
```

---
---
emoji: üõ°Ô∏è
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# üõ°Ô∏è Backend: Motor PII Participa DF

## üîí Seguran√ßa do Token Hugging Face (HF_TOKEN)

> **IMPORTANTE:**
> - O token Hugging Face **NUNCA** deve ser colocado no c√≥digo-fonte nem em arquivos versionados (ex: .env, settings.py, etc).
> - Use sempre o arquivo `.env` (N√ÉO versionado) para armazenar o token localmente ou no deploy.
> - O arquivo `.env.example` serve apenas de modelo e pode ir para o GitHub, mas sem o token real.
> - O backend j√° l√™ automaticamente o `.env` e injeta o token no pipeline do transformers.
> - No deploy Hugging Face Spaces, configure o token como vari√°vel de ambiente ou suba um `.env` manualmente (N√ÉO envie para o reposit√≥rio).

**Resumo:**
- O token √© lido em tempo de execu√ß√£o, nunca aparece no log nem no c√≥digo.
- O projeto est√° seguro para uso p√∫blico e privado, desde que siga essas orienta√ß√µes.

## üÜï Integra√ß√£o Gazetteer GDF (v9.5)

O motor agora integra um **gazetteer institucional do GDF** (arquivo `gazetteer_gdf.json`) para filtrar falsos positivos de nomes, √≥rg√£os, escolas, hospitais e programas p√∫blicos. Isso garante que entidades institucional n√£o sejam marcadas como PII, elevando a precis√£o em contexto Bras√≠lia/DF.

**Como funciona:**
- O arquivo `src/gazetteer_gdf.json` cont√©m listas de √≥rg√£os, siglas, aliases, escolas e hospitais do GDF.
- O detector carrega todos os nomes/siglas/aliases e ignora qualquer entidade que bata exata ou parcialmente com o gazetteer.
- Logs informam quando uma entidade √© ignorada por match no gazetteer.

**Impacto no benchmark:**
- F1-Score mantido em 0.9763 (excelente, sem aumento de FP/FN)
- Nenhum novo falso positivo ou negativo foi introduzido
- Todos os FPs/FNs remanescentes s√£o casos conhecidos de padr√µes GDF, n√£o relacionados ao filtro institucional

**Como editar/expandir:**
- Edite `src/gazetteer_gdf.json` para adicionar novos √≥rg√£os, escolas, hospitais, programas ou aliases.
- O formato √© autoexplicativo e suporta m√∫ltiplos aliases por entidade.

**Exemplo de entrada:**
```json
{
    "orgaos": [
        {"nome": "Secretaria de Educa√ß√£o do DF", "sigla": "SEEDF", "aliases": ["Educa√ß√£o DF", "Secretaria Educa√ß√£o"]},
        {"nome": "DETRAN-DF", "sigla": "DETRAN", "aliases": ["Departamento de Tr√¢nsito"]}
    ],
    "escolas": [
        {"nome": "Centro de Ensino Fundamental 01 do Guar√°", "sigla": "CEF 01", "aliases": ["CEF Guar√°"]}
    ]
}
```

**Arquivo:** `backend/src/gazetteer_gdf.json`

---

[![Python](https://img.shields.io/badge/Python-3.10+-yellow?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![spaCy](https://img.shields.io/badge/spaCy-3.8.0-09A3D5?logo=spacy)](https://spacy.io/)
[![Vers√£o](https://img.shields.io/badge/Vers√£o-9.4.3-blue)](./src/detector.py)
[![F1--Score](https://img.shields.io/badge/F1--Score-1.0000-success)](./benchmark.py)

> **Motor h√≠brido de detec√ß√£o de Informa√ß√µes Pessoais Identific√°veis (PII)** para conformidade LGPD/LAI em manifesta√ß√µes do Participa DF.
> üèÜ **v9.4.3 - F1-Score = 1.0000** (100% precis√£o, 100% sensibilidade) em benchmark de 303 casos LGPD.
>
> üÜï **v9.4.3**: 5 n√≠veis de risco LGPD (CR√çTICO ‚Üí BAIXO), 30+ tipos de PII, IP/Coordenadas/User-Agent, contadores globais.

| üåê **Links de Produ√ß√£o** | URL |
|--------------------------|-----|
| API Base | https://marinhothiago-desafio-participa-df.hf.space/ |
| Documenta√ß√£o Interativa | https://marinhothiago-desafio-participa-df.hf.space/docs |
| Health Check | https://marinhothiago-desafio-participa-df.hf.space/health |

---

## üìã Objetivo do Backend

Detectar, classificar e avaliar o risco de vazamento de dados pessoais em textos de manifesta√ß√µes do Participa DF, retornando:

- **Classifica√ß√£o:** "P√öBLICO" ou "N√ÉO P√öBLICO"
- **N√≠vel de Risco:** SEGURO, BAIXO, MODERADO, ALTO, CR√çTICO (5 n√≠veis LGPD)
- **Confian√ßa:** Score normalizado (0.0 a 1.0)
- **Detalhes:** Lista de PIIs encontrados com tipo, valor e confian√ßa

### Funcionalidades Principais

- ‚úÖ **Rastreabilidade Total:** Preserva o ID original do e-SIC em todo o fluxo
- ‚úÖ **Motor H√≠brido v9.4.3:** Ensemble de Regex + BERT Davlan + NuNER + spaCy + Regras
- ‚úÖ **30+ Tipos de PII:** Documentos, contatos, financeiros, sa√∫de, biometria, localiza√ß√£o
- ‚úÖ **Confian√ßa Probabil√≠stica:** Calibra√ß√£o isot√¥nica + combina√ß√£o log-odds
- ‚úÖ **Tr√™s Formas de Uso:** API REST, Interface CLI (lote) e integra√ß√£o com Dashboard Web
- ‚úÖ **Valida√ß√£o de Documentos:** CPF, CNPJ, PIS, CNS com d√≠gito verificador
- ‚úÖ **Contexto Bras√≠lia/GDF:** Imunidade funcional para servidores p√∫blicos em exerc√≠cio
- ‚úÖ **Contadores Globais:** Persist√™ncia em stats.json com thread-safety

---

## üìÅ Estrutura de Arquivos e Fun√ß√£o de Cada Componente

```
backend/
‚îú‚îÄ‚îÄ README.md                 ‚Üê ESTE ARQUIVO: Documenta√ß√£o t√©cnica
‚îú‚îÄ‚îÄ requirements.txt          ‚Üê Depend√™ncias Python (pip install -r)
‚îú‚îÄ‚îÄ Dockerfile                ‚Üê Container para deploy em HuggingFace
‚îú‚îÄ‚îÄ docker-compose.yml        ‚Üê Orquestra√ß√£o local com frontend
‚îÇ
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           ‚Üê Marca como m√≥dulo Python
‚îÇ   ‚îî‚îÄ‚îÄ main.py               ‚Üê FastAPI: endpoints /analyze e /health
‚îÇ                               (135 linhas, coment√°rios detalhados)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           ‚Üê Marca como m√≥dulo Python
‚îÇ   ‚îú‚îÄ‚îÄ detector.py           ‚Üê Motor h√≠brido PII v9.4.3
‚îÇ   ‚îÇ                           (2100+ linhas com coment√°rios explicativos)
‚îÇ   ‚îÇ                           - Classe PIIDetector: ensemble de detectores
‚îÇ   ‚îÇ                           - Classe ValidadorDocumentos: valida√ß√£o DV
‚îÇ   ‚îÇ                           - Regex patterns para 30+ tipos de PII
‚îÇ   ‚îÇ                           - NER: BERT Davlan + NuNER + spaCy
‚îÇ   ‚îÇ                           - Regras de neg√≥cio (imunidade funcional)
‚îÇ   ‚îÇ                           - M√©todo detect_extended() com confian√ßa prob.
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ allow_list.py         ‚Üê Lista de termos seguros (375 termos)
‚îÇ   ‚îÇ                           - √ìrg√£os do GDF (SEEDF, SESDF, DETRAN, etc)
‚îÇ   ‚îÇ                           - Regi√µes administrativas de Bras√≠lia
‚îÇ   ‚îÇ                           - Endere√ßos administrativos (SQS, SQN, etc)
‚îÇ   ‚îÇ                           - Confian√ßa base por tipo de PII
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ confidence/           ‚Üê NOVO: M√≥dulo de confian√ßa probabil√≠stica
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py       ‚Üê Exports do m√≥dulo
‚îÇ       ‚îú‚îÄ‚îÄ types.py          ‚Üê PIIEntity, DocumentConfidence, SourceDetection
‚îÇ       ‚îú‚îÄ‚îÄ config.py         ‚Üê FN_RATES, FP_RATES, PESOS_LGPD, thresholds
‚îÇ       ‚îú‚îÄ‚îÄ validators.py     ‚Üê Valida√ß√£o DV (CPF, CNPJ, PIS, CNS, etc)
‚îÇ       ‚îú‚îÄ‚îÄ calibration.py    ‚Üê IsotonicCalibrator, CalibratorRegistry
‚îÇ       ‚îú‚îÄ‚îÄ combiners.py      ‚Üê ProbabilityCombiner, EntityAggregator
‚îÇ       ‚îî‚îÄ‚îÄ calculator.py     ‚Üê PIIConfidenceCalculator (orquestrador)
‚îÇ
‚îú‚îÄ‚îÄ main_cli.py               ‚Üê CLI para processamento em lote
‚îÇ                               - Entrada: CSV/XLSX com coluna "Texto Mascarado"
‚îÇ                               - Sa√≠da: JSON + CSV + XLSX com cores
‚îÇ
‚îú‚îÄ‚îÄ benchmark.py              ‚Üê üèÜ Benchmark LGPD: 303 casos de teste
‚îÇ                               - F1-Score = 1.0000 (100% P/R)
‚îÇ                               - Casos seguros (n√£o PII)
‚îÇ                               - PIIs cl√°ssicos (CPF, Email, Telefone)
‚îÇ                               - Edge cases de Bras√≠lia/GDF
‚îÇ                               - Imunidade funcional
‚îÇ
‚îú‚îÄ‚îÄ test_confianca.py         ‚Üê Testes do sistema de confian√ßa
‚îÇ                               - Valida√ß√£o de d√≠gitos verificadores
‚îÇ                               - Calibra√ß√£o isot√¥nica
‚îÇ                               - Combina√ß√£o log-odds
‚îÇ
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ input/                ‚Üê Arquivos para processar em lote
    ‚îî‚îÄ‚îÄ output/               ‚Üê Relat√≥rios gerados
        ‚îú‚îÄ‚îÄ resultado.json    ‚Üê Dados estruturados
        ‚îú‚îÄ‚îÄ resultado.csv     ‚Üê Planilha simples
        ‚îî‚îÄ‚îÄ resultado.xlsx    ‚Üê Excel com formata√ß√£o de cores
```

---

## 1Ô∏è‚É£ INSTRU√á√ïES DE INSTALA√á√ÉO E DEPEND√äNCIAS

### 1.1 Pr√©-requisitos

| Software | Vers√£o M√≠nima | Verificar | Como Instalar |
|----------|---------------|-----------|---------------|
| **Python** | 3.10+ | `python --version` | [python.org](https://www.python.org/downloads/) |
| **pip** | 23.0+ | `pip --version` | Inclu√≠do com Python |
| **Git** | 2.0+ | `git --version` | [git-scm.com](https://git-scm.com/) |

**Requisitos de Sistema:**
- **RAM:** M√≠nimo 4GB (recomendado 8GB para modelos NLP)
- **Disco:** ~3GB (modelos spaCy + BERT)
- **Internet:** Necess√°ria para download inicial dos modelos

### 1.2 Arquivo de Depend√™ncias: `requirements.txt`

```txt
# ===========================================
# Participa DF - Backend Requirements
# Python 3.10 (compat√≠vel com spaCy 3.8)
# ===========================================

# === Framework Web ===
fastapi==0.110.0              # API REST ass√≠ncrona
uvicorn==0.27.1               # Servidor ASGI de alta performance
python-multipart==0.0.9       # Upload de arquivos

# === Processamento de Dados ===
pandas==2.2.1                 # Manipula√ß√£o de DataFrames
openpyxl==3.1.2               # Leitura/escrita de Excel

# === NLP Core ===
spacy==3.8.0                  # NLP para portugu√™s (pt_core_news_lg)
text-unidecode==1.3           # Normaliza√ß√£o de strings

# === Transformers + PyTorch (CPU) ===
transformers==4.41.2          # BERT NER multil√≠ngue
sentencepiece==0.1.99         # Tokeniza√ß√£o
accelerate>=0.21.0            # Otimiza√ß√£o de infer√™ncia

# NOTA: PyTorch instalado separadamente no Dockerfile
# pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu
```

### 1.3 Instala√ß√£o Passo a Passo

```bash
# 1. Clone o reposit√≥rio (se ainda n√£o fez)
git clone https://github.com/marinhothiago/desafio-participa-df.git
cd desafio-participa-df/backend

# 2. Crie ambiente virtual Python
python -m venv venv

# 3. Ative o ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Instale PyTorch CPU (ANTES das outras depend√™ncias)
pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu

# 5. Instale todas as depend√™ncias
pip install -r requirements.txt

# 6. Baixe o modelo spaCy para portugu√™s (OBRIGAT√ìRIO)
python -m spacy download pt_core_news_lg

# 7. (Opcional) Verifique a instala√ß√£o
python -c "import spacy; nlp = spacy.load('pt_core_news_lg'); print('‚úÖ spaCy OK')"
python -c "from transformers import pipeline; print('‚úÖ Transformers OK')"
```

**Tempo estimado:** 5-10 minutos (primeira instala√ß√£o)

---

## 2Ô∏è‚É£ INSTRU√á√ïES DE EXECU√á√ÉO

### 2.1 Servidor API (FastAPI)

```bash
# Certifique-se de estar na pasta backend/
cd backend

# Ative o ambiente virtual (se n√£o estiver ativo)
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Inicie o servidor
uvicorn api.main:app --host 0.0.0.0 --port 7860 --reload
```

**Sa√≠da esperada:**
```
INFO:     üèÜ [v9.4.3] VERS√ÉO HACKATHON - ENSEMBLE 5 FONTES + CONFIAN√áA PROBABIL√çSTICA
INFO:     ‚úÖ spaCy pt_core_news_lg carregado
INFO:     ‚úÖ BERT Davlan NER multil√≠ngue carregado (PER, ORG, LOC, DATE)
INFO:     ‚úÖ NuNER pt-BR carregado (especializado em portugu√™s)
INFO:     Uvicorn running on http://0.0.0.0:7860 (Press CTRL+C to quit)
```

**Endpoints dispon√≠veis:**
| Endpoint | M√©todo | Descri√ß√£o |
|----------|--------|-----------|
| `/analyze` | POST | Analisa texto para detec√ß√£o de PII |
| `/health` | GET | Verifica status da API |
| `/docs` | GET | Documenta√ß√£o Swagger interativa |
| `/redoc` | GET | Documenta√ß√£o ReDoc |

### 2.2 CLI (Processamento em Lote)

```bash
# Ative o ambiente virtual
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate

# Execute o processamento
python main_cli.py --input data/input/manifestacoes.xlsx --output data/output/resultado
```

**Argumentos:**
| Argumento | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-----------|------|-------------|-----------|
| `--input` | string | ‚úÖ | Caminho do arquivo CSV ou XLSX |
| `--output` | string | ‚úÖ | Nome base dos arquivos de sa√≠da |

**Arquivos gerados (todos com mesma estrutura de colunas):**
| Arquivo | Formato | Uso |
|---------|---------|-----|
| `resultado.json` | JSON | Integra√ß√£o com sistemas, APIs |
| `resultado.csv` | CSV UTF-8 | Importa√ß√£o em outras ferramentas |
| `resultado.xlsx` | Excel | An√°lise visual com cores por risco |

**Colunas de sa√≠da (ordem padronizada):**
1. `ID` - Identificador original do registro
2. `Texto Mascarado` - Texto analisado
3. `Classifica√ß√£o` - ‚úÖ P√öBLICO ou ‚ùå N√ÉO P√öBLICO
4. `Confian√ßa` - Percentual de certeza (ex: 98.5%)
5. `N√≠vel de Risco` - SEGURO, BAIXO, MODERADO, ALTO, CR√çTICO
6. `Identificadores` - Lista de PIIs detectados

### 2.3 Execu√ß√£o com Docker

```bash
# Na pasta backend/
docker build -t desafio-participa-df-backend .

# Execute o container
docker run -p 7860:7860 desafio-participa-df-backend
```

**Ou usando docker-compose (da raiz do projeto):**
```bash
cd ..  # volta para a raiz
docker-compose up backend
```

---

## üìä Formato de Dados

### Endpoints Dispon√≠veis

| Endpoint | M√©todo | Descri√ß√£o |
|----------|--------|-----------|
| `/analyze` | POST | Analisa texto para detec√ß√£o de PII |
| `/health` | GET | Verifica status da API |
| `/stats` | GET | Retorna estat√≠sticas globais de uso |
| `/stats/visit` | POST | Registra uma visita ao site |

### Estat√≠sticas Globais (v9.4)

**GET /stats** - Retorna contadores globais:
```json
{
  "site_visits": 1234,
  "classification_requests": 5678,
  "last_updated": "2026-01-16T10:30:00"
}
```

**POST /stats/visit** - Registra visita (chamado 1x por sess√£o do frontend):
```json
{
  "site_visits": 1235,
  "classification_requests": 5678,
  "last_updated": "2026-01-16T10:31:00"
}
```

> **Nota:** O contador `classification_requests` √© incrementado automaticamente a cada chamada ao `/analyze`.

### Entrada (POST /analyze)

```json
{
  "text": "Meu CPF √© 123.456.789-09 e preciso de ajuda urgente.",
  "id": "manifestacao_001"
}
```

| Campo | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-------|------|-------------|-----------|
| `text` | string | ‚úÖ Sim | Texto a ser analisado (m√°x 10.000 caracteres) |
| `id` | string | ‚ùå N√£o | ID para rastreabilidade (preservado na sa√≠da) |

### Sa√≠da

```json
{
  "id": "manifestacao_001",
  "classificacao": "N√ÉO P√öBLICO",
  "risco": "CR√çTICO",
  "confianca": 0.98,
  "detalhes": [
    {
      "tipo": "CPF",
      "valor": "123.456.789-09",
      "confianca": 1.0
    }
  ]
}
```

| Campo | Tipo | Valores | Descri√ß√£o |
|-------|------|---------|-----------|
| `id` | string | qualquer | ID preservado da entrada |
| `classificacao` | string | "P√öBLICO", "N√ÉO P√öBLICO" | Se pode publicar |
| `risco` | string | SEGURO, BAIXO, MODERADO, ALTO, CR√çTICO | Severidade |
| `confianca` | float | 0.0 - 1.0 | Certeza do modelo (normalizado) |
| `detalhes` | array | objetos | Lista de PIIs encontrados |

### Formato de Arquivo para CLI (CSV/XLSX)

O arquivo deve conter uma coluna `Texto Mascarado` (ou `text`):

```csv
ID,Texto Mascarado
man_001,"Solicito informa√ß√µes sobre minha situa√ß√£o cadastral."
man_002,"Meu CPF √© 529.982.247-25 e telefone (61) 98765-4321."
man_003,"Reclama√ß√£o contra o servidor Jo√£o Silva do DETRAN."
```

**Sa√≠da do CLI (mesma estrutura nos 3 formatos):**

```csv
ID,Texto Mascarado,Classifica√ß√£o,Confian√ßa,N√≠vel de Risco,Identificadores
man_001,"Solicito informa√ß√µes...","‚úÖ P√öBLICO","100.0%","SEGURO","[]"
man_002,"Meu CPF √© 529.982.247-25...","‚ùå N√ÉO P√öBLICO","98.0%","CR√çTICO","['CPF: 529.982.247-25', 'TELEFONE: (61) 98765-4321']"
```

```json
[
  {
    "id": "man_001",
    "texto_mascarado": "Solicito informa√ß√µes...",
    "classificacao": "‚úÖ P√öBLICO",
    "confianca": "100.0%",
    "nivel_risco": "SEGURO",
    "identificadores": "[]"
  },
  {
    "id": "man_002",
    "texto_mascarado": "Meu CPF √© 529.982.247-25...",
    "classificacao": "‚ùå N√ÉO P√öBLICO",
    "confianca": "98.0%",
    "nivel_risco": "CR√çTICO",
    "identificadores": "['CPF: 529.982.247-25', 'TELEFONE: (61) 98765-4321']"
  }
]
```

---

## üß† Arquitetura do Motor de Detec√ß√£o (v9.4.3)

### Pipeline de Processamento

```
Texto de Entrada
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CAMADA 1: REGEX                           ‚îÇ
‚îÇ  ‚Ä¢ CPF (com valida√ß√£o de d√≠gito verificador)                 ‚îÇ
‚îÇ  ‚Ä¢ CNPJ, PIS, CNS, T√≠tulo de Eleitor (valida√ß√£o DV)         ‚îÇ
‚îÇ  ‚Ä¢ RG, CNH, Passaporte, CTPS, Certid√µes                     ‚îÇ
‚îÇ  ‚Ä¢ Email pessoal (exclui .gov.br, .org.br, .edu.br)         ‚îÇ
‚îÇ  ‚Ä¢ Telefone (fixo, celular, DDI)                             ‚îÇ
‚îÇ  ‚Ä¢ Endere√ßo residencial, CEP                                 ‚îÇ
‚îÇ  ‚Ä¢ Dados banc√°rios, PIX, Cart√£o de cr√©dito                   ‚îÇ
‚îÇ  ‚Ä¢ Placa de ve√≠culo (Mercosul e antiga)                      ‚îÇ
‚îÇ  ‚Ä¢ Data de nascimento, IP Address                            ‚îÇ
‚îÇ  ‚Ä¢ Texto com gatilhos de contato (ex: "falar com", "ligar para")‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA 2: BERT NER (prim√°rio)                   ‚îÇ
‚îÇ  Modelo: Davlan/bert-base-multilingual-cased-ner-hrl        ‚îÇ
‚îÇ  ‚Ä¢ Detector prim√°rio de nomes pessoais (PER)                 ‚îÇ
‚îÇ  ‚Ä¢ Threshold de confian√ßa: 0.75                              ‚îÇ
‚îÇ  ‚Ä¢ Filtros: nome + sobrenome, n√£o em blocklist               ‚îÇ
‚îÇ  ‚Ä¢ Verifica imunidade funcional antes de marcar              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            CAMADA 3: spaCy (complementar)                    ‚îÇ
‚îÇ  Modelo: pt_core_news_lg (portugu√™s)                         ‚îÇ
‚îÇ  ‚Ä¢ Captura nomes que o BERT n√£o detectou                     ‚îÇ
‚îÇ  ‚Ä¢ Roda em paralelo, n√£o √© fallback                          ‚îÇ
‚îÇ  ‚Ä¢ Evita duplicatas: s√≥ adiciona se BERT n√£o encontrou       ‚îÇ
‚îÇ  ‚Ä¢ Mesmos filtros de qualidade                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              CAMADA 4: REGRAS DE NEG√ìCIO                     ‚îÇ
‚îÇ  ‚Ä¢ Gatilhos de contato: "falar com", "ligar para"           ‚îÇ
‚îÇ    ‚Üí Nome ap√≥s gatilho = SEMPRE PII                          ‚îÇ
‚îÇ  ‚Ä¢ Imunidade funcional: "Dr. Jo√£o da Secretaria"             ‚îÇ
‚îÇ    ‚Üí Servidor em contexto funcional = N√ÉO PII                ‚îÇ
‚îÇ  ‚Ä¢ Contexto Bras√≠lia: SQS, SQN, Eixo = endere√ßo p√∫blico     ‚îÇ
‚îÇ  ‚Ä¢ Blocklist: sauda√ß√µes, termos administrativos              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ENSEMBLE OR + DEDUPLICA√á√ÉO                  ‚îÇ
‚îÇ  ‚Ä¢ Combina achados de todas as camadas                       ‚îÇ
‚îÇ  ‚Ä¢ Remove duplicatas priorizando maior peso                  ‚îÇ
‚îÇ  ‚Ä¢ Calcula risco m√°ximo e confian√ßa composta                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
   Resultado Final
   (classificacao, risco, confianca, detalhes)
```

### Sistema de Confian√ßa Composta

A confian√ßa de cada PII detectado √© calculada dinamicamente:

```
confian√ßa_final = min(1.0, confian√ßa_base √ó fator_contexto)
```

#### Confian√ßa Base por M√©todo

| M√©todo | Tipos | Base | Justificativa |
|--------|-------|------|---------------|
| **Regex + DV** | CPF, PIS, CNS, CNH, T√≠tulo Eleitor, CTPS | 0.98 | Valida√ß√£o matem√°tica |
| **Regex + Luhn** | Cart√£o Cr√©dito | 0.95 | Algoritmo v√°lido |
| **Regex estrutural** | Email, Telefone, Placa, PIX | 0.85-0.95 | Padr√£o claro |
| **Regex + contexto** | CEP, Data Nascimento | 0.70-0.75 | Depende de contexto |
| **BERT NER** | Nomes | score do modelo | Retorna 0.75-0.99 |
| **spaCy NER** | Nomes | 0.70 | Modelo complementar |
| **Gatilho** | Nomes ap√≥s "falar com" | 0.85 | Padr√£o lingu√≠stico |

#### Fatores de Contexto

| Fator | Ajuste | Exemplo |
|-------|--------|---------|
| Possessivo | +15% | "**Meu** CPF √©..." |
| Label expl√≠cito | +10% | "**CPF:** 529..." |
| Verbo declarativo | +5% | "CPF **√©** 529..." |
| Gatilho de contato | +10% | "**falar com** Jo√£o" |
| Contexto de teste | -25% | "**exemplo**: 000..." |
| Declarado fict√≠cio | -30% | "CPF **fict√≠cio**" |
| Nega√ß√£o | -20% | "**n√£o √©** meu CPF" |
| Institucional | -10% | "CPF **da empresa**" |

#### Exemplos de C√°lculo

```python
# Exemplo 1: CPF com possessivo e label
texto = "Meu CPF: 529.982.247-25"
base = 0.98  # DV v√°lido
fator = 1.0 + 0.15 (possessivo) + 0.10 (label) = 1.25
confianca = min(1.0, 0.98 * 1.25) = 1.0  # Capped

# Exemplo 2: CPF em contexto de exemplo
texto = "exemplo de CPF: 529.982.247-25"
base = 0.98
fator = 1.0 - 0.25 (exemplo) = 0.75
confianca = 0.98 * 0.75 = 0.74  # Baixa, pode ser filtrado

# Exemplo 3: Nome detectado por BERT com gatilho
texto = "falar com Jo√£o Silva"
base = 0.87  # Score do BERT
fator = 1.0 + 0.10 (gatilho) = 1.10
confianca = min(1.0, 0.87 * 1.10) = 0.96
```

### Tipos de PII Detectados

| Categoria | Tipos | Peso | Valida√ß√£o |
|-----------|-------|------|-----------|
| **Documentos** | CPF, RG, CNH, Passaporte, PIS, CNS, CNPJ (MEI), T√≠tulo Eleitor, CTPS, Certid√µes | 5 (Cr√≠tico) | D√≠gito Verificador |
| **Contato** | Email pessoal, Telefone, Celular | 4 (Alto) | Regex + exclus√£o institucional |
| **Localiza√ß√£o** | Endere√ßo residencial, CEP | 4 (Alto) | Contexto "moro", "resido" |
| **Financeiro** | Conta banc√°ria, PIX, Cart√£o de cr√©dito | 4 (Alto) | Padr√µes estruturados |
| **Identifica√ß√£o** | Nome completo, Nome em contexto | 3-4 | BERT NER + regras |
| **Outros** | Placa de ve√≠culo, Data nascimento, IP | 3 (Moderado) | Regex |

### Imunidade Funcional (LAI)

Servidores p√∫blicos em exerc√≠cio de fun√ß√£o **N√ÉO s√£o PII**:
- ‚úÖ "A Dra. Maria da Secretaria de Sa√∫de informou que..."
- ‚úÖ "O servidor Jos√© Santos do DETRAN atendeu a demanda"
- ‚úÖ "Funcion√°rio do m√™s: Pedro Oliveira"

**Gatilhos que ANULAM imunidade:**
- ‚ùå "Preciso falar com o Jo√£o Silva sobre isso"
- ‚ùå "Ligar para a Dra. Maria no celular"
- ‚ùå "Endere√ßo da Maria: Rua das Flores, 123"

---

## üß™ Testes e Benchmark

```bash
# Na pasta backend/, com ambiente virtual ativo

# Execute o benchmark LGPD (303 casos, F1=1.0)
python benchmark.py

# Execute os testes de confian√ßa
python test_confianca.py
```

**Benchmark LGPD (303 casos - F1-Score = 1.0000):**

| Grupo | Quantidade | Esperado | Descri√ß√£o |
|-------|------------|----------|-----------|
| Administrativo | 50+ | P√öBLICO | Textos burocr√°ticos sem PII |
| PII Cl√°ssico | 80+ | N√ÉO P√öBLICO | CPF, Email, Telefone, RG, etc |
| Nomes | 40+ | Variado | Nomes com contexto funcional vs pessoal |
| Edge Cases | 50+ | Variado | Situa√ß√µes amb√≠guas, Bras√≠lia/GDF |
| Imunidade | 30+ | P√öBLICO | Servidores em exerc√≠cio |
| Gatilhos | 25+ | N√ÉO P√öBLICO | "falar com", "ligar para" |
| Documentos DV | 25+ | N√ÉO P√öBLICO | CPF, CNPJ, PIS, CNS com valida√ß√£o |

---

## üê≥ Dockerfile

```dockerfile
# Python 3.10 slim para menor tamanho
FROM python:3.10-slim

# Vari√°veis de ambiente
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# Depend√™ncias do sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential curl && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Instala PyTorch CPU
RUN pip install --no-cache-dir torch==2.1.0+cpu \
    --index-url https://download.pytorch.org/whl/cpu

# Instala depend√™ncias Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Baixa modelo spaCy
RUN pip install --no-cache-dir \
    https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.8.0/pt_core_news_lg-3.8.0-py3-none-any.whl

# Pr√©-download BERT NER
RUN python -c "from transformers import pipeline; \
    pipeline('ner', model='Davlan/bert-base-multilingual-cased-ner-hrl')"

# Copia c√≥digo
COPY . .

# Porta HuggingFace Spaces
EXPOSE 7860

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:7860/health || exit 1

# Comando de inicializa√ß√£o
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "7860"]
```

---

## üìö C√≥digo Fonte Comentado

### Exemplo: Motor de Detec√ß√£o (`src/detector.py`)

```python
class PIIDetector:
    """Detector h√≠brido de PII com ensemble de alta recall.
    
    Estrat√©gia: Ensemble OR - qualquer detector positivo classifica como PII.
    Isso maximiza recall (n√£o deixar escapar nenhum PII) √†s custas de alguns
    falsos positivos, que √© a estrat√©gia correta para LAI/LGPD.
    """

    def __init__(self, usar_gpu: bool = True) -> None:
        """Inicializa o detector com todos os modelos NLP.
        
        Args:
            usar_gpu: Se True, usa CUDA quando dispon√≠vel
        """
        logger.info("üèÜ [v9.2] F1-Score = 1.0000 - Benchmark LGPD")
        
        self.validador = ValidadorDocumentos()
        self._inicializar_modelos(usar_gpu)
        self._inicializar_vocabularios()
        self._compilar_patterns()

    def detect(self, text: str) -> Tuple[bool, List[Dict], str, float]:
        """Detecta PII no texto usando ensemble de alta recall.
        
        Pipeline:
        1. Regex com valida√ß√£o de DV (documentos)
        2. Extra√ß√£o de nomes ap√≥s gatilhos de contato
        3. NER com BERT + spaCy (nomes e entidades)
        4. Deduplica√ß√£o com prioridade por peso
        
        Args:
            text: Texto a ser analisado
            
        Returns:
            Tuple com:
            - is_pii (bool): True se cont√©m PII
            - findings (List[Dict]): PIIs encontrados
            - nivel_risco (str): CRITICO, ALTO, MODERADO, BAIXO, SEGURO
            - confianca (float): Score 0-1 normalizado
        """
```

### Exemplo: API FastAPI (`api/main.py`)

```python
@app.post("/analyze")
async def analyze(data: Dict[str, Optional[str]]) -> Dict:
    """Analisa texto para detec√ß√£o de PII com contexto Bras√≠lia/GDF.
    
    Realiza detec√ß√£o h√≠brida usando:
    - Regex: Padr√µes estruturados (CPF, Email, Telefone, RG, CNH)
    - NLP: Reconhecimento de entidades com spaCy + BERT
    - Regras de Neg√≥cio: Contexto de Bras√≠lia, imunidade funcional (LAI)
    
    Args:
        data: Dict com "text" (obrigat√≥rio) e "id" (opcional)
    
    Returns:
        Dict com classificacao, risco, confianca e detalhes
    """
```

---

## üèóÔ∏è Arquitetura Atualizada (2026)

O backend agora conta com tr√™s grandes pilares para detec√ß√£o e explica√ß√£o de PII:

- **Pipeline H√≠brido Original:** Regex, valida√ß√£o DV, BERT Davlan, NuNER pt-BR, spaCy, gazetteer, regras, confian√ßa probabil√≠stica, thresholds din√¢micos, p√≥s-processamento.
- **Presidio Framework (Microsoft):** Detec√ß√£o PII modular, multi-idioma, f√°cil manuten√ß√£o e expans√£o de entidades, integra√ß√£o via `detect_pii_presidio`.
- **√Årbitro LLM (Llama-70B via Hugging Face Inference API):** Explica√ß√£o e arbitragem de casos amb√≠guos, fallback para edge cases, integra√ß√£o via Hugging Face Inference API.

O resultado final pode ser uma fus√£o (ensemble) dos detectores, com explica√ß√£o detalhada e m√°xima cobertura.

Veja exemplos de uso das novas fun√ß√µes e como customizar detectores no final deste README.

---

## ü§ñ Arbitragem com LLM (Llama-70B via Hugging Face)

O backend possui integra√ß√£o opcional com Llama-70B (Hugging Face Inference API) para arbitragem de casos amb√≠guos de PII.

- Use a fun√ß√£o `arbitrate_with_llama(texto, achados)` para obter decis√£o e explica√ß√£o detalhada de um LLM.
- Ideal para casos de baixa confian√ßa, empate entre detectores ou explica√ß√£o avan√ßada para humanos.
- O token Hugging Face j√° utilizado no projeto √© aproveitado para autentica√ß√£o.

Exemplo:
```python
from src.detector import arbitrate_with_llama

decision, explanation = arbitrate_with_llama(texto, achados)
print(decision, explanation)
```

---


## Integra√ß√£o Modular Presidio + ONNX (v9.5+)

A partir da vers√£o 9.5, **TODO O MOTOR DE DETEC√á√ÉO FOI CENTRALIZADO NO FRAMEWORK [Presidio Analyzer](https://microsoft.github.io/presidio/)**, com todos os regex e NER registrados como Recognizers customizados. Isso garante:

- **Auditoria e rastreabilidade total**: cada achado traz fonte, score, explica√ß√£o e logs.
- **Expans√£o e manuten√ß√£o facilitadas**: adicionar/ajustar entidades = s√≥ registrar novo Recognizer.
- **Performance m√°xima**: integra√ß√£o nativa com ONNX para BERT NER (quando dispon√≠vel), fallback autom√°tico para pipelines originais (transformers, spaCy, NuNER).
- **Pol√≠tica de agrega√ß√£o e deduplica√ß√£o**: resultados s√£o agregados por span, priorizando maior score e explica√ß√£o detalhada (campo `explanation`).
- **Seguran√ßa do token Hugging Face**: Uso obrigat√≥rio de `.env` (n√£o versionado), carregamento autom√°tico em todos os entrypoints, nunca exposto em c√≥digo ou log.

### Como funciona

1. **Regex ‚Üí PatternRecognizer**: Todos os padr√µes (CPF, CNPJ, RG, etc) agora s√£o PatternRecognizers do Presidio, com valida√ß√£o DV opcional.
2. **NER ‚Üí EntityRecognizer**: BERT, NuNER e spaCy s√£o registrados como EntityRecognizers customizados, cada um com sua pipeline.
3. **BERT NER via ONNX**: Se o modelo ONNX estiver presente (`backend/models/bert_ner_onnx/model.onnx`), o Recognizer usa infer√™ncia otimizada via `optimum.onnxruntime`. Caso contr√°rio, usa pipeline transformers padr√£o.
4. **Agrega√ß√£o**: Todos os achados s√£o deduplicados por span, priorizando maior score e explica√ß√£o detalhada (campo `explanation`).
5. **Fallback e logs**: Se algum Recognizer falhar, logs detalhados s√£o emitidos e o sistema continua com os demais.

### Exemplo de uso: detec√ß√£o PII centralizada

```python
from src.detector import detect_pii_presidio

texto = "Meu CPF √© 123.456.789-00 e meu telefone √© (61) 99999-8888."
resultados = detect_pii_presidio(texto, entities=None, language='pt')
for r in resultados:
  print(r)
# Sa√≠da: [{'entity': 'CPF', 'score': 0.98, ...}, {'entity': 'TELEFONE_DDI', ...}, ...]
```

#### Exemplo: uso avan√ßado com agrega√ß√£o e explica√ß√£o

```python
from src.detector import PIIDetector

detector = PIIDetector()
achados = detector.detect_presidio_ensemble("Falar com Jo√£o Silva, CPF 123.456.789-00", entities=None)
for a in achados:
  print(a['entity'], a['score'], a['explanation'])
# Sa√≠da: NOME 0.97 Detectado por ONNX_BERT_NER_Recognizer (score=0.97)
#        CPF 1.0 Detectado por PatternRecognizer (score=1.00)
```

### Como expandir: registrando novos Recognizers

Para adicionar um novo padr√£o ou NER:

```python
from presidio_analyzer import Pattern, PatternRecognizer, EntityRecognizer

# Exemplo: novo padr√£o para matr√≠cula funcional
pattern = Pattern(name="MATRICULA_FUNCIONAL", regex=r"\b\d{7,8}[A-Z]?\b", score=0.90)
recognizer = PatternRecognizer(supported_entity="MATRICULA_FUNCIONAL", patterns=[pattern])
detector.presidio_analyzer.registry.add_recognizer(recognizer)

# Exemplo: novo NER customizado
class MeuNERRecognizer(EntityRecognizer):
  def __init__(self, nlp_pipeline, entity_label):
    super().__init__(supported_entities=[entity_label], name="MeuNERRecognizer")
    self.nlp_pipeline = nlp_pipeline
  def analyze(self, text, entities, nlp_artifacts=None):
    # ... l√≥gica customizada ...
    return results
detector.presidio_analyzer.registry.add_recognizer(MeuNERRecognizer(...))
```

### Vantagens
- **Auditoria LGPD**: Cada achado traz fonte, score, explica√ß√£o e logs.
- **Expans√£o f√°cil**: Basta registrar novo Recognizer, sem alterar o core.
- **Performance**: ONNX acelera BERT NER em at√© 5x (CPU), sem perder precis√£o.
- **Fallback robusto**: Se ONNX n√£o dispon√≠vel, usa pipeline transformers/spaCy/NuNER.
- **Agrega√ß√£o e explica√ß√£o**: Pol√≠tica de deduplica√ß√£o e explica√ß√£o detalhada por span.

### Instala√ß√£o e depend√™ncias

J√° incluso em `requirements.txt`:

```
presidio-analyzer
optimum[onnx]
onnxruntime
```

Para exportar o modelo BERT NER para ONNX:

```
pip install optimum[onnx] onnxruntime
optimum-cli export onnx --model Davlan/bert-base-multilingual-cased-ner-hrl backend/models/bert_ner_onnx/
```

Mais detalhes: [Documenta√ß√£o oficial Presidio](https://microsoft.github.io/presidio/analyzer/)

---

## üóÇÔ∏è Fluxograma Arquitetural Atualizado

```mermaid
flowchart TD
  A[Texto de Entrada] --> B[Presidio AnalyzerEngine]
  B --> C1[PatternRecognizers (Regex + Valida√ß√£o DV)]
  B --> C2[EntityRecognizers (BERT NER ONNX, NuNER, spaCy)]
  C2 --> D1[ONNX BERT NER (se dispon√≠vel)]
  C2 --> D2[Transformers Pipeline (fallback)]
  C2 --> D3[NuNER Pipeline]
  C2 --> D4[spaCy Pipeline]
  B --> E[Agrega√ß√£o/Deduplica√ß√£o + Explica√ß√£o]
  E --> F[Resultado Final: achados, score, explica√ß√£o, fonte]
```

---
