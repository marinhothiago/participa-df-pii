---
title: Participa DF - Detector Inteligente de Dados Pessoais
emoji: ðŸ›¡ï¸
colorFrom: blue
colorTo: green
sdk: docker
app_file: api/main.py
pinned: false
---

# ðŸ›¡ï¸ Backend: Motor PII Participa DF v9.5.0

[![Python](https://img.shields.io/badge/Python-3.10+-yellow?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![spaCy](https://img.shields.io/badge/spaCy-3.8.0-09A3D5?logo=spacy)](https://spacy.io/)
[![VersÃ£o](https://img.shields.io/badge/VersÃ£o-9.5.0-blue)](./src/detector.py)
[![F1--Score](https://img.shields.io/badge/F1--Score-1.0000-success)](./tests/test_benchmark.py)
[![Testes](https://img.shields.io/badge/Testes-410%20passando-brightgreen)](./tests/)

> **Motor hÃ­brido de detecÃ§Ã£o de InformaÃ§Ãµes Pessoais IdentificÃ¡veis (PII)** para conformidade LGPD/LAI em manifestaÃ§Ãµes do Participa DF.
> 
> ðŸ† **v9.5.0 - F1-Score = 1.0000** (100% precisÃ£o, 100% sensibilidade) em benchmark de 308 casos LGPD + 5 casos LLM Ã¡rbitro.
>
> ðŸ†• **v9.5.0**: Ãrbitro LLM Llama-3.2-3B-Instruct via `huggingface_hub`, 410 testes passando, reorganizaÃ§Ã£o do projeto.

| ðŸŒ **Links de ProduÃ§Ã£o** | URL |
|--------------------------|-----|
| API Base | https://marinhothiago-desafio-participa-df.hf.space/ |
| DocumentaÃ§Ã£o Interativa | https://marinhothiago-desafio-participa-df.hf.space/docs |
| Health Check | https://marinhothiago-desafio-participa-df.hf.space/health |

---

## ðŸš€ MELHORIAS E FUNCIONALIDADES AVANÃ‡ADAS (2025-2026)

- ðŸ›ï¸ **Gazetteer institucional GDF:** Filtro de falsos positivos para nomes de Ã³rgÃ£os, escolas, hospitais e aliases do DF, editÃ¡vel via `src/gazetteer/gazetteer_gdf.json`. Garante mÃ¡xima precisÃ£o em contexto BrasÃ­lia/DF.
- ðŸ§  **Sistema de confianÃ§a probabilÃ­stica:** CalibraÃ§Ã£o isotÃ´nica + log-odds, thresholds dinÃ¢micos por tipo, fatores de contexto, explicaÃ§Ã£o detalhada abaixo.
- âš¡ **PÃ³s-processamento de spans:** NormalizaÃ§Ã£o, merge/split, deduplicaÃ§Ã£o de entidades para mÃ¡xima precisÃ£o.
- ðŸ† **Benchmark LGPD/LAI:** 410+ testes, F1-score 1.0000, incluindo 5 casos de Ã¡rbitro LLM.
- ðŸ¤– **Ãrbitro LLM (Llama-3.2-3B-Instruct):** Desativado por padrÃ£o (opt-in) - arbitragem inteligente de casos ambÃ­guos via `huggingface_hub`. Ative com `PII_USE_LLM_ARBITRATION=True`.
- ðŸ”’ **SeguranÃ§a do token Hugging Face:** Uso obrigatÃ³rio de `.env` (nÃ£o versionado), carregamento automÃ¡tico em todos os entrypoints, nunca exposto em cÃ³digo ou log.
- ðŸ§¹ **Limpeza e organizaÃ§Ã£o:** `.gitignore` e `.dockerignore` revisados, scripts de limpeza, deploy seguro, documentaÃ§Ã£o atualizada.
- ðŸ³ **Deploy profissional:** Docker Compose, Hugging Face Spaces, checklist de produÃ§Ã£o.

---

## ðŸ› ï¸ Troubleshooting & Edge Cases (Presidio/ONNX)

### Erros comuns e soluÃ§Ãµes rÃ¡pidas

- **ImportError: 'optimum.onnxruntime' could not be resolved**
  - SoluÃ§Ã£o: Execute `pip install optimum[onnx] onnxruntime` no seu ambiente virtual.
  - Dica: Sempre ative o venv antes de instalar (`source venv/bin/activate` ou `venv\Scripts\activate`).

- **Presidio nÃ£o encontra Recognizers customizados**
  - SoluÃ§Ã£o: Verifique se o mÃ©todo `_compilar_patterns` foi chamado no construtor do `PIIDetector`.
  - Dica: Veja logs de inicializaÃ§Ã£o para "Recognizer registrado".

- **ONNX nÃ£o Ã© usado mesmo com modelo exportado**
  - SoluÃ§Ã£o: Confirme se o arquivo `backend/models/bert_ner_onnx/model.onnx` existe e estÃ¡ acessÃ­vel.
  - Dica: Veja logs para "ONNX NER carregado". Se falhar, o fallback para transformers Ã© automÃ¡tico.

- **Erro de importaÃ§Ã£o de allow_list ou gazetteer**
  - SoluÃ§Ã£o: Confirme se os arquivos/mÃ³dulos estÃ£o no diretÃ³rio correto (`src/`). Use imports relativos no backend.

- **Problemas de performance (CPU alto, resposta lenta)**
  - Dica: ONNX acelera BERT NER em atÃ© 5x. Se nÃ£o estiver usando, revise dependÃªncias e modelo exportado.

- **Reconhecedores customizados nÃ£o detectam entidades**
  - SoluÃ§Ã£o: Adicione prints/logs no mÃ©todo `analyze` do seu Recognizer para depurar entradas e saÃ­das.
  - Dica: Use `logger.warning` para mensagens visÃ­veis em produÃ§Ã£o.

- **Logs nÃ£o aparecem**
  - SoluÃ§Ã£o: Certifique-se que o logger estÃ¡ configurado no inÃ­cio do projeto (`logging.basicConfig(level=logging.INFO)`).

### Edge Cases e dicas avanÃ§adas

- O fallback para pipelines transformers/spaCy/NuNER Ã© automÃ¡tico se ONNX falhar.
- Todos os Recognizers customizados podem ser removidos/adicionados em tempo de execuÃ§Ã£o via registry do Presidio.
- Para debugging profundo, ative logs DEBUG no inÃ­cio do app:
  ```python
  import logging
  logging.basicConfig(level=logging.DEBUG)
  ```
- Para auditar decisÃµes, cada achado traz o campo `explanation` e `source`.
- Para expandir entidades, basta registrar um novo Recognizer (nÃ£o precisa alterar o core).

### Links Ãºteis
- [Presidio Analyzer Docs](https://microsoft.github.io/presidio/analyzer/)
- [Optimum ONNX Export](https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model)
- [Exemplo de Recognizer customizado](https://microsoft.github.io/presidio/analyzer/development/adding_recognizers/)

---

## ðŸ†• EstratÃ©gias de Merge de Spans (Presets)

A partir da versÃ£o 9.4.3+, o endpoint `/analyze` permite escolher a estratÃ©gia de merge de spans (entidades sobrepostas) via parÃ¢metro `merge_preset`:

- `recall`: MantÃ©m todos os spans sobrepostos (maximiza recall, Ãºtil para auditoria).
- `precision`: MantÃ©m apenas o span com maior score/confianÃ§a (maximiza precisÃ£o, Ãºtil para produÃ§Ã£o).
- `f1`: MantÃ©m o span mais longo por sobreposiÃ§Ã£o (equilÃ­brio entre recall e precisÃ£o, padrÃ£o).
- `custom`: Permite lÃ³gica customizada (exemplo: priorizar fonte especÃ­fica ou lÃ³gica prÃ³pria).

### Como usar na API

```http
POST /analyze?merge_preset=recall
Content-Type: application/json
{
  "text": "Meu CPF Ã© 123.456.789-09 e meu telefone Ã© 99999-8888"
}
```

- `merge_preset` pode ser: `recall`, `precision`, `f1`, `custom` (default: `f1`)
- O resultado em `detalhes` refletirÃ¡ a estratÃ©gia escolhida.

### Exemplos de uso via curl

```bash
# Maximizar recall (todos spans):

# Maximizar precisÃ£o (apenas maior score):
curl -X POST "http://localhost:8000/analyze?merge_preset=precision" -H "Content-Type: application/json" -d '{"text": "Meu CPF Ã© 123.456.789-09"}'

# Customizado:
```

### ObservaÃ§Ãµes
- O merge sÃ³ Ã© aplicado se as entidades retornadas tiverem `start` e `end` (posiÃ§Ã£o no texto).
- Para uso avanÃ§ado, consulte `src/confidence/combiners.py` e ajuste a funÃ§Ã£o `merge_spans_custom`.
- O preset `custom` pode ser expandido para lÃ³gica prÃ³pria no backend.

---
# ðŸ“š COMO USAR AS NOVAS FUNCIONALIDADES
### Gazetteer GDF
- Edite `src/gazetteer_gdf.json` para adicionar Ã³rgÃ£os, escolas, hospitais, programas ou aliases. O detector ignora entidades que batem com o gazetteer, reduzindo FPs em contexto institucional.

- Execute `python scripts/optimize_ensemble.py` para buscar os melhores pesos do ensemble. O script reusa o detector e valida o F1-score automaticamente.
### SeguranÃ§a do Token Hugging Face
- Crie um `.env` (NÃƒO versionado) com `HF_TOKEN=seu_token`. O backend carrega automaticamente. Nunca exponha o token em cÃ³digo ou log.

- [x] `.env` nunca versionado
- [x] Modelos baixados no build do Docker
- [x] Scripts de limpeza nÃ£o vÃ£o para produÃ§Ã£o
- [x] Testes e benchmark executados antes do deploy
```bash
python scripts/main_cli.py --input data/input/manifestacoes.xlsx --output data/output/resultado

# Rodar benchmark completo

python pos_processar_spans.py --input data/output/resultado.json --output data/output/resultado_pos.json
```

---
---
emoji: ðŸ›¡ï¸
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
---

# ðŸ›¡ï¸ Backend: Motor PII Participa DF

## ðŸ”’ SeguranÃ§a do Token Hugging Face (HF_TOKEN)

> **IMPORTANTE:**
> - O token Hugging Face **NUNCA** deve ser colocado no cÃ³digo-fonte nem em arquivos versionados (ex: .env, settings.py, etc).
> - Use sempre o arquivo `.env` (NÃƒO versionado) para armazenar o token localmente ou no deploy.
> - O arquivo `.env.example` serve apenas de modelo e pode ir para o GitHub, mas sem o token real.
> - O backend jÃ¡ lÃª automaticamente o `.env` e injeta o token no pipeline do transformers.
> - No deploy Hugging Face Spaces, configure o token como variÃ¡vel de ambiente ou suba um `.env` manualmente (NÃƒO envie para o repositÃ³rio).

**Resumo:**
- O token Ã© lido em tempo de execuÃ§Ã£o, nunca aparece no log nem no cÃ³digo.
- O projeto estÃ¡ seguro para uso pÃºblico e privado, desde que siga essas orientaÃ§Ãµes.

---

## ðŸ¤– Ãrbitro LLM: Llama-3.2-3B-Instruct (v9.5.0)

O motor de detecÃ§Ã£o agora conta com um **Ãrbitro LLM (Llama-3.2-3B-Instruct)** que Ã© acionado automaticamente em casos ambÃ­guos para melhorar a precisÃ£o e reduzir falsos negativos.

### Status: âœ… ATIVADO POR PADRÃƒO

A partir da versÃ£o 9.5.0, o Ã¡rbitro LLM estÃ¡ **desativado por padrÃ£o** (`use_llm_arbitration=False`) para evitar custos. Para ativar, use a variÃ¡vel de ambiente `PII_USE_LLM_ARBITRATION=True`. Usa a biblioteca oficial `huggingface_hub` com `InferenceClient`.

### Quando o LLAMA Ã© Acionado

O Ã¡rbitro Ã© chamado automaticamente em dois cenÃ¡rios:

1. **Itens com baixa confianÃ§a**: Quando um PII Ã© detectado mas a confianÃ§a estÃ¡ abaixo do threshold, o LLAMA analisa o contexto e decide se deve ser incluÃ­do.

2. **Zero PIIs encontrados**: Quando o ensemble nÃ£o encontra nenhum PII, o LLAMA faz uma anÃ¡lise final do texto completo como "Ãºltima chance".

### Fluxo de DecisÃ£o

```
INPUT (texto)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ensemble Executa   â”‚  BERT + NuNER + spaCy + Regex
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VotaÃ§Ã£o + Thresholdâ”‚  Itens com confianÃ§a baixa â†’ _pendentes_llm
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PIIs  â”‚  â”‚ Baixa confianÃ§a/ â”‚
â”‚ OK    â”‚  â”‚ Zero PIIs        â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚               â”‚
    â”‚               â–¼
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      â”‚ LLAMA-3.2-3B   â”‚  AnÃ¡lise contextual LGPD/LAI
    â”‚      â”‚ ÃRBITRO        â”‚  Prompt em portuguÃªs
    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚               â”‚
    â”‚          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚          â”‚         â”‚
    â”‚          â–¼         â–¼
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
    â”‚      â”‚ PII  â”‚  â”‚ NÃƒO  â”‚
    â”‚      â”‚      â”‚  â”‚ PII  â”‚
    â”‚      â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜
    â”‚         â”‚         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Resultado Final    â”‚  has_pii, entities, risk_level
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ConfiguraÃ§Ã£o

#### VariÃ¡veis de Ambiente

```bash
# .env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx              # OBRIGATÃ“RIO para LLAMA funcionar
HF_MODEL=meta-llama/Llama-3.2-3B-Instruct      # Opcional (este Ã© o padrÃ£o)
PII_USE_LLM_ARBITRATION=True                   # PadrÃ£o: False (ative para usar LLM)
PII_USAR_GPU=True                              # Usar GPU se disponÃ­vel
```

> **Nota**: Modelos alternativos disponÃ­veis: `meta-llama/Llama-3.1-70B-Instruct` (mais preciso, mais lento)

#### Desativar LLAMA (opcional)

Para testes rÃ¡pidos ou ambientes sem HF_TOKEN:

```bash
# Desativar via variÃ¡vel de ambiente
PII_USE_LLM_ARBITRATION=True
```

Ou no cÃ³digo:

```python
detector = PIIDetector(use_llm_arbitration=False)
```

#### ForÃ§ar LLAMA em uma chamada especÃ­fica

```python
# Usar LLAMA mesmo se desativado globalmente
resultado, findings, risco, confianca = detector.detect(texto, force_llm=True)
```

### Requisitos

| Requisito | Detalhe |
|-----------|---------|
| **HF_TOKEN** | Token do Hugging Face (criar em https://huggingface.co/settings/tokens) |
| **huggingface_hub** | Biblioteca Python (`pip install huggingface_hub`) |
| **Aceitar Termos** | Aceitar termos do Llama em https://huggingface.co/meta-llama |
| **ConexÃ£o** | Internet para chamar a Hugging Face Inference API |

### Fail-Safe (EstratÃ©gia de Falha)

Se o LLAMA nÃ£o responder (timeout, erro de API, etc):

- **Itens pendentes**: SÃ£o INCLUÃDOS no resultado (evita falso negativo)
- **Log**: Warning Ã© emitido para monitoramento
- **Resultado**: Sistema continua funcionando sem interrupÃ§Ã£o

### Endpoint da API

O endpoint `/analyze` suporta o parÃ¢metro `use_llm`:

```http
POST /analyze?use_llm=true
Content-Type: application/json

{
  "text": "Texto ambÃ­guo para analisar"
}
```

### Modelo Utilizado

- **Modelo**: `meta-llama/Llama-3.2-3B-Instruct` (configurÃ¡vel via `HF_MODEL`)
- **Biblioteca**: `huggingface_hub` (InferenceClient)
- **MÃ©todo**: `client.chat_completion()` com formato messages
- **Prompt**: PortuguÃªs, com instruÃ§Ãµes LGPD/LAI especÃ­ficas
- **Temperatura**: 0.1 (respostas determinÃ­sticas)
- **Max Tokens**: 150

### Impacto no Benchmark

| MÃ©trica | Sem LLAMA | Com LLAMA |
|---------|-----------|-----------|
| PrecisÃ£o | 1.0000 | 1.0000 |
| Sensibilidade | 1.0000 | 1.0000 |
| F1-Score | 1.0000 | 1.0000 |
| LatÃªncia mÃ©dia | ~200ms | ~500-2000ms* |

*LatÃªncia aumenta apenas quando LLAMA Ã© acionado (casos ambÃ­guos).

---

## ðŸ†• IntegraÃ§Ã£o Gazetteer GDF (v9.5)

O motor agora integra um **gazetteer institucional do GDF** (arquivo `gazetteer_gdf.json`) para filtrar falsos positivos de nomes, Ã³rgÃ£os, escolas, hospitais e programas pÃºblicos. Isso garante que entidades institucional nÃ£o sejam marcadas como PII, elevando a precisÃ£o em contexto BrasÃ­lia/DF.

**Como funciona:**
- O arquivo `src/gazetteer_gdf.json` contÃ©m listas de Ã³rgÃ£os, siglas, aliases, escolas e hospitais do GDF.
- O detector carrega todos os nomes/siglas/aliases e ignora qualquer entidade que bata exata ou parcialmente com o gazetteer.
- Logs informam quando uma entidade Ã© ignorada por match no gazetteer.

**Impacto no benchmark:**
- F1-Score mantido em 0.9763 (excelente, sem aumento de FP/FN)
- Nenhum novo falso positivo ou negativo foi introduzido
- Todos os FPs/FNs remanescentes sÃ£o casos conhecidos de padrÃµes GDF, nÃ£o relacionados ao filtro institucional

**Como editar/expandir:**
- Edite `src/gazetteer_gdf.json` para adicionar novos Ã³rgÃ£os, escolas, hospitais, programas ou aliases.
- O formato Ã© autoexplicativo e suporta mÃºltiplos aliases por entidade.

**Exemplo de entrada:**
```json
{
    "orgaos": [
        {"nome": "Secretaria de EducaÃ§Ã£o do DF", "sigla": "SEEDF", "aliases": ["EducaÃ§Ã£o DF", "Secretaria EducaÃ§Ã£o"]},
        {"nome": "DETRAN-DF", "sigla": "DETRAN", "aliases": ["Departamento de TrÃ¢nsito"]}
    ],
    "escolas": [
        {"nome": "Centro de Ensino Fundamental 01 do GuarÃ¡", "sigla": "CEF 01", "aliases": ["CEF GuarÃ¡"]}
    ]
}
```

**Arquivo:** `backend/src/gazetteer_gdf.json`

---

[![Python](https://img.shields.io/badge/Python-3.10+-yellow?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![spaCy](https://img.shields.io/badge/spaCy-3.8.0-09A3D5?logo=spacy)](https://spacy.io/)
[![VersÃ£o](https://img.shields.io/badge/VersÃ£o-9.5.0-blue)](./src/detector.py)
[![F1--Score](https://img.shields.io/badge/F1--Score-1.0000-success)](./benchmark.py)

> **Motor hÃ­brido de detecÃ§Ã£o de InformaÃ§Ãµes Pessoais IdentificÃ¡veis (PII)** para conformidade LGPD/LAI em manifestaÃ§Ãµes do Participa DF.
> ðŸ† **v9.5.0 - F1-Score = 1.0000** (100% precisÃ£o, 100% sensibilidade) em benchmark de 308 casos LGPD + 5 casos LLM Ã¡rbitro.
>
> ðŸ†• **v9.5.0**: Ãrbitro LLM Llama-3.2-3B-Instruct, 410 testes passando, integraÃ§Ã£o `huggingface_hub`.

| ðŸŒ **Links de ProduÃ§Ã£o** | URL |
|--------------------------|-----|
| API Base | https://marinhothiago-desafio-participa-df.hf.space/ |
| DocumentaÃ§Ã£o Interativa | https://marinhothiago-desafio-participa-df.hf.space/docs |
| Health Check | https://marinhothiago-desafio-participa-df.hf.space/health |

---

## ðŸ“‹ Objetivo do Backend
Detectar, classificar e avaliar o risco de vazamento de dados pessoais em textos de manifestaÃ§Ãµes do Participa DF, retornando:

- **Novo formato de resposta (API v2):**
  ```json
  {
    "has_pii": true,
    "entities": [
      {"tipo": "CPF", "valor": "123.456.789-09", "confianca": 0.98, "fonte": "regex"}
    ],
    "risk_level": "ALTO",
    "confidence_all_found": 0.97,
    "total_entities": 1,
    "sources_used": ["regex", "bert_ner"]
  }
  ```

- **Principais campos:**
  - `has_pii`: se encontrou dado pessoal
  - `entities`: lista detalhada de entidades (tipo, valor, confianÃ§a, fonte)
  - `risk_level`: nÃ­vel de risco LGPD
  - `confidence_all_found`: confianÃ§a global
  - `total_entities`: total de entidades detectadas
  - `sources_used`: fontes usadas na detecÃ§Ã£o

**AtenÃ§Ã£o:** O frontend agora deve consumir este novo formato. O formato antigo (tupla) foi descontinuado.

### Funcionalidades Principais

- âœ… **Pipeline hÃ­brido avanÃ§ado:** Regex, validaÃ§Ã£o DV, BERT NER, NuNER, spaCy, gazetteer institucional, regras de negÃ³cio, pÃ³s-processamento, ensemble/fusÃ£o, calibradores probabilÃ­sticos e thresholds dinÃ¢micos.
- âœ… **Presets de merge de spans:** recall, precision, f1, custom (ajustÃ¡vel via parÃ¢metro na API).
- âœ… **Gazetteer institucional GDF:** filtro de falsos positivos para nomes de Ã³rgÃ£os, escolas, hospitais e aliases do DF.
- âœ… **Sistema de confianÃ§a probabilÃ­stica:** calibraÃ§Ã£o isotÃ´nica, combinaÃ§Ã£o log-odds, thresholds dinÃ¢micos por tipo, explicabilidade total.
- âœ… **Ãrbitro LLM (opt-in):** explicaÃ§Ã£o e decisÃ£o em casos ambÃ­guos (Llama-3.2-3B-Instruct via `huggingface_hub`). Ative com `PII_USE_LLM_ARBITRATION=True`.
- âœ… **30+ Tipos de PII:** documentos, contatos, financeiros, saÃºde, biometria, localizaÃ§Ã£o.
- âœ… **Rastreabilidade Total:** preserva o ID original do e-SIC em todo o fluxo.
- âœ… **Contadores Globais:** persistÃªncia em stats.json com thread-safety.

---

## ðŸ§ª ESTRATÃ‰GIA DE TESTES

- **Cobertura total:** edge cases, benchmark LGPD, anÃ¡lise de confianÃ§a, integraÃ§Ã£o, regressÃ£o.
- **Testes unitÃ¡rios:** funÃ§Ãµes isoladas (regex, validadores, calibradores).
- **Testes de integraÃ§Ã£o:** fluxo completo (detector + confianÃ§a + API).
- **Testes de benchmark:** performance, recall, precisÃ£o, F1-score.
- **Testes de filtragem:** robustez contra falsos positivos/negativos.

Todos os testes podem ser executados via `pytest` no backend.

---

## ðŸš¦ INTEGRAÃ‡ÃƒO FRONTEND

1. Consuma o novo formato de resposta (dicionÃ¡rio estruturado, ver exemplo acima).
2. Ajuste o parsing dos campos: use `has_pii`, `entities`, `risk_level`, `confidence_all_found`, etc.
3. Aproveite os novos campos para exibir mais detalhes (confianÃ§a por entidade, fontes, etc).
4. Remova qualquer dependÃªncia do formato antigo (tupla).
5. Teste todos os fluxos do frontend.

Consulte o README.md da raiz para instruÃ§Ãµes de migraÃ§Ã£o e exemplos de uso.

---

## ðŸ“ Estrutura de Arquivos e FunÃ§Ã£o de Cada Componente

```
backend/
â”œâ”€â”€ README.md                 â† ESTE ARQUIVO: DocumentaÃ§Ã£o tÃ©cnica
â”œâ”€â”€ requirements.txt          â† DependÃªncias Python (pip install -r)
â”œâ”€â”€ Dockerfile                â† Container para deploy em HuggingFace
â”œâ”€â”€ docker-compose.yml        â† OrquestraÃ§Ã£o local com frontend
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py           â† Marca como mÃ³dulo Python
â”‚   â””â”€â”€ main.py               â† FastAPI: endpoints /analyze e /health
â”‚                               (135 linhas, comentÃ¡rios detalhados)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py           â† Marca como mÃ³dulo Python
â”‚   â”œâ”€â”€ detector.py           â† Motor hÃ­brido PII v9.5.0
â”‚   â”‚                           (2100+ linhas com comentÃ¡rios explicativos)
â”‚   â”‚                           - Classe PIIDetector: ensemble de detectores
â”‚   â”‚                           - Classe ValidadorDocumentos: validaÃ§Ã£o DV
â”‚   â”‚                           - Regex patterns para 30+ tipos de PII
â”‚   â”‚                           - NER: BERT Davlan + NuNER + spaCy
â”‚   â”‚                           - Regras de negÃ³cio (imunidade funcional)
â”‚   â”‚                           - MÃ©todo detect_extended() com confianÃ§a prob.
â”‚   â”‚
â”‚   â”œâ”€â”€ allow_list.py         â† Lista de termos seguros (375 termos)
â”‚   â”‚                           - Ã“rgÃ£os do GDF (SEEDF, SESDF, DETRAN, etc)
â”‚   â”‚                           - RegiÃµes administrativas de BrasÃ­lia
â”‚   â”‚                           - EndereÃ§os administrativos (SQS, SQN, etc)
â”‚   â”‚                           - ConfianÃ§a base por tipo de PII
â”‚   â”‚
â”‚   â””â”€â”€ confidence/           â† NOVO: MÃ³dulo de confianÃ§a probabilÃ­stica
â”‚       â”œâ”€â”€ __init__.py       â† Exports do mÃ³dulo
â”‚       â”œâ”€â”€ types.py          â† PIIEntity, DocumentConfidence, SourceDetection
â”‚       â”œâ”€â”€ config.py         â† FN_RATES, FP_RATES, PESOS_LGPD, thresholds
â”‚       â”œâ”€â”€ validators.py     â† ValidaÃ§Ã£o DV (CPF, CNPJ, PIS, CNS, etc)
â”‚       â”œâ”€â”€ calibration.py    â† IsotonicCalibrator, CalibratorRegistry
â”‚       â”œâ”€â”€ combiners.py      â† ProbabilityCombiner, EntityAggregator
â”‚       â””â”€â”€ calculator.py     â† PIIConfidenceCalculator (orquestrador)
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py               â† FastAPI: endpoints /analyze e /health
â”‚   â”œâ”€â”€ celery_config.py      â† ConfiguraÃ§Ã£o Celery + Redis
â”‚   â””â”€â”€ tasks.py              â† Tasks assÃ­ncronas para lotes
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main_cli.py           â† CLI para processamento em lote
â”‚   â”‚                           - Entrada: CSV/XLSX com coluna "Texto Mascarado"
â”‚   â”‚                           - SaÃ­da: JSON + CSV + XLSX com cores
â”‚   â”‚
â”‚   â”œâ”€â”€ optimize_ensemble.py  â† Grid search de pesos do ensemble
â”‚   â”œâ”€â”€ clean_backend.ps1     â† Limpeza de cache do backend
â”‚   â””â”€â”€ clean_frontend.ps1    â† Limpeza de cache do frontend
â”‚
â”œâ”€â”€ tests/                    â† Testes automatizados (pytest)
â”‚   â”œâ”€â”€ test_benchmark.py     â† ðŸ† Benchmark LGPD: 303 casos, F1=1.0000
â”‚   â”œâ”€â”€ test_amostra.py       â† Testes com amostra e-SIC
â”‚   â”œâ”€â”€ test_confianca.py     â† Testes do sistema de confianÃ§a
â”‚   â”œâ”€â”€ test_edge_cases.py    â† Casos extremos e edge cases
â”‚   â””â”€â”€ ...                   â† Outros testes especializados
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ input/                â† Arquivos para processar em lote
    â””â”€â”€ output/               â† RelatÃ³rios gerados
        â”œâ”€â”€ resultado.json    â† Dados estruturados
        â”œâ”€â”€ resultado.csv     â† Planilha simples
        â””â”€â”€ resultado.xlsx    â† Excel com formataÃ§Ã£o de cores
```

---

## 1ï¸âƒ£ INSTRUÃ‡Ã•ES DE INSTALAÃ‡ÃƒO E DEPENDÃŠNCIAS

### 1.1 PrÃ©-requisitos

| Software | VersÃ£o MÃ­nima | Verificar | Como Instalar |
|----------|---------------|-----------|---------------|
| **Python** | 3.10+ | `python --version` | [python.org](https://www.python.org/downloads/) |
| **pip** | 23.0+ | `pip --version` | IncluÃ­do com Python |
| **Git** | 2.0+ | `git --version` | [git-scm.com](https://git-scm.com/) |

**Requisitos de Sistema:**
- **RAM:** MÃ­nimo 4GB (recomendado 8GB para modelos NLP)
- **Disco:** ~3GB (modelos spaCy + BERT)
- **Internet:** NecessÃ¡ria para download inicial dos modelos

### 1.2 Arquivo de DependÃªncias: `requirements.txt`

```txt
# ===========================================
# Participa DF - Backend Requirements
# Python 3.10 (compatÃ­vel com spaCy 3.8)
# ===========================================

# === Framework Web ===
fastapi==0.110.0              # API REST assÃ­ncrona
uvicorn==0.27.1               # Servidor ASGI de alta performance
python-multipart==0.0.9       # Upload de arquivos

# === Processamento de Dados ===
pandas==2.2.1                 # ManipulaÃ§Ã£o de DataFrames
openpyxl==3.1.2               # Leitura/escrita de Excel

# === NLP Core ===
spacy==3.8.0                  # NLP para portuguÃªs (pt_core_news_lg)
text-unidecode==1.3           # NormalizaÃ§Ã£o de strings

# === Transformers + PyTorch (CPU) ===
transformers==4.41.2          # BERT NER multilÃ­ngue
sentencepiece==0.1.99         # TokenizaÃ§Ã£o
accelerate>=0.21.0            # OtimizaÃ§Ã£o de inferÃªncia

# NOTA: PyTorch instalado separadamente no Dockerfile
# pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu
```

### 1.3 InstalaÃ§Ã£o Passo a Passo

```bash
# 1. Clone o repositÃ³rio (se ainda nÃ£o fez)
git clone https://github.com/marinhothiago/desafio-participa-df.git
cd desafio-participa-df/backend

# 2. Crie ambiente virtual Python
python -m venv venv

# 3. Ative o ambiente virtual
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Instale PyTorch CPU (ANTES das outras dependÃªncias)
pip install torch==2.1.0+cpu --index-url https://download.pytorch.org/whl/cpu

# 5. Instale todas as dependÃªncias
pip install -r requirements.txt

# 6. Baixe o modelo spaCy para portuguÃªs (OBRIGATÃ“RIO)
python -m spacy download pt_core_news_lg

# 7. (Opcional) Verifique a instalaÃ§Ã£o
python -c "import spacy; nlp = spacy.load('pt_core_news_lg'); print('âœ… spaCy OK')"
python -c "from transformers import pipeline; print('âœ… Transformers OK')"
```

**Tempo estimado:** 5-10 minutos (primeira instalaÃ§Ã£o)

---

## 2ï¸âƒ£ INSTRUÃ‡Ã•ES DE EXECUÃ‡ÃƒO

### 2.1 Servidor API (FastAPI)

```bash
# Certifique-se de estar na pasta backend/
cd backend

# Ative o ambiente virtual (se nÃ£o estiver ativo)
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Inicie o servidor
uvicorn api.main:app --host 0.0.0.0 --port 7860 --reload
```

**SaÃ­da esperada:**
```
INFO:     ðŸ† [v9.5.0] VERSÃƒO HACKATHON - ENSEMBLE 5 FONTES + CONFIANÃ‡A PROBABILÃSTICA + LLM ÃRBITRO
INFO:     âœ… spaCy pt_core_news_lg carregado
INFO:     âœ… BERT Davlan NER multilÃ­ngue carregado (PER, ORG, LOC, DATE)
INFO:     âœ… NuNER pt-BR carregado (especializado em portuguÃªs)
INFO:     Uvicorn running on http://0.0.0.0:7860 (Press CTRL+C to quit)
```

**Endpoints disponÃ­veis:**
| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/analyze` | POST | Analisa texto para detecÃ§Ã£o de PII |
| `/health` | GET | Verifica status da API |
| `/docs` | GET | DocumentaÃ§Ã£o Swagger interativa |
| `/redoc` | GET | DocumentaÃ§Ã£o ReDoc |

### 2.2 CLI (Processamento em Lote)

```bash
# Ative o ambiente virtual
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate

# Execute o processamento
python scripts/main_cli.py --input data/input/manifestacoes.xlsx --output data/output/resultado
```

**Argumentos:**
| Argumento | Tipo | ObrigatÃ³rio | DescriÃ§Ã£o |
|-----------|------|-------------|-----------|
| `--input` | string | âœ… | Caminho do arquivo CSV ou XLSX |
| `--output` | string | âœ… | Nome base dos arquivos de saÃ­da |

**Arquivos gerados (todos com mesma estrutura de colunas):**
| Arquivo | Formato | Uso |
|---------|---------|-----|
| `resultado.json` | JSON | IntegraÃ§Ã£o com sistemas, APIs |
| `resultado.csv` | CSV UTF-8 | ImportaÃ§Ã£o em outras ferramentas |
| `resultado.xlsx` | Excel | AnÃ¡lise visual com cores por risco |

**Colunas de saÃ­da (ordem padronizada):**
1. `ID` - Identificador original do registro
2. `Texto Mascarado` - Texto analisado
3. `ClassificaÃ§Ã£o` - âœ… PÃšBLICO ou âŒ NÃƒO PÃšBLICO
4. `ConfianÃ§a` - Percentual de certeza (ex: 98.5%)
5. `NÃ­vel de Risco` - SEGURO, BAIXO, MODERADO, ALTO, CRÃTICO
6. `Identificadores` - Lista de PIIs detectados

### 2.3 ExecuÃ§Ã£o com Docker

```bash
# Na pasta backend/
docker build -t desafio-participa-df-backend .

# Execute o container
docker run -p 7860:7860 desafio-participa-df-backend
```

**Ou usando docker-compose (da raiz do projeto):**
```bash
cd ..  # volta para a raiz
docker-compose up backend
```

---

## ðŸ“Š Formato de Dados

### Endpoints DisponÃ­veis

| Endpoint | MÃ©todo | DescriÃ§Ã£o |
|----------|--------|-----------|
| `/analyze` | POST | Analisa texto para detecÃ§Ã£o de PII |
| `/health` | GET | Verifica status da API |
| `/stats` | GET | Retorna estatÃ­sticas globais de uso |
| `/stats/visit` | POST | Registra uma visita ao site |

### EstatÃ­sticas Globais (v9.4)

**GET /stats** - Retorna contadores globais:
```json
{
  "site_visits": 1234,
  "classification_requests": 5678,
  "last_updated": "2026-01-16T10:30:00"
}
```

**POST /stats/visit** - Registra visita (chamado 1x por sessÃ£o do frontend):
```json
{
  "site_visits": 1235,
  "classification_requests": 5678,
  "last_updated": "2026-01-16T10:31:00"
}
```

> **Nota:** O contador `classification_requests` Ã© incrementado automaticamente a cada chamada ao `/analyze`.

### Entrada (POST /analyze)

```json
{
  "text": "Meu CPF Ã© 123.456.789-09 e preciso de ajuda urgente.",
  "id": "manifestacao_001"
}
```

| Campo | Tipo | ObrigatÃ³rio | DescriÃ§Ã£o |
|-------|------|-------------|-----------|
| `text` | string | âœ… Sim | Texto a ser analisado (mÃ¡x 10.000 caracteres) |
| `id` | string | âŒ NÃ£o | ID para rastreabilidade (preservado na saÃ­da) |

### SaÃ­da

```json
{
  "id": "manifestacao_001",
  "classificacao": "NÃƒO PÃšBLICO",
  "risco": "CRÃTICO",
  "confianca": 0.98,
  "detalhes": [
    {
      "tipo": "CPF",
      "valor": "123.456.789-09",
      "confianca": 1.0
    }
  ]
}
```

| Campo | Tipo | Valores | DescriÃ§Ã£o |
|-------|------|---------|-----------|
| `id` | string | qualquer | ID preservado da entrada |
| `classificacao` | string | "PÃšBLICO", "NÃƒO PÃšBLICO" | Se pode publicar |
| `risco` | string | SEGURO, BAIXO, MODERADO, ALTO, CRÃTICO | Severidade |
| `confianca` | float | 0.0 - 1.0 | Certeza do modelo (normalizado) |
| `detalhes` | array | objetos | Lista de PIIs encontrados |

### Formato de Arquivo para CLI (CSV/XLSX)

O arquivo deve conter uma coluna `Texto Mascarado` (ou `text`):

```csv
ID,Texto Mascarado
man_001,"Solicito informaÃ§Ãµes sobre minha situaÃ§Ã£o cadastral."
man_002,"Meu CPF Ã© 529.982.247-25 e telefone (61) 98765-4321."
man_003,"ReclamaÃ§Ã£o contra o servidor JoÃ£o Silva do DETRAN."
```

**SaÃ­da do CLI (mesma estrutura nos 3 formatos):**

```csv
ID,Texto Mascarado,ClassificaÃ§Ã£o,ConfianÃ§a,NÃ­vel de Risco,Identificadores
man_001,"Solicito informaÃ§Ãµes...","âœ… PÃšBLICO","100.0%","SEGURO","[]"
man_002,"Meu CPF Ã© 529.982.247-25...","âŒ NÃƒO PÃšBLICO","98.0%","CRÃTICO","['CPF: 529.982.247-25', 'TELEFONE: (61) 98765-4321']"
```

```json
[
  {
    "id": "man_001",
    "texto_mascarado": "Solicito informaÃ§Ãµes...",
    "classificacao": "âœ… PÃšBLICO",
    "confianca": "100.0%",
    "nivel_risco": "SEGURO",
    "identificadores": "[]"
  },
  {
    "id": "man_002",
    "texto_mascarado": "Meu CPF Ã© 529.982.247-25...",
    "classificacao": "âŒ NÃƒO PÃšBLICO",
    "confianca": "98.0%",
    "nivel_risco": "CRÃTICO",
    "identificadores": "['CPF: 529.982.247-25', 'TELEFONE: (61) 98765-4321']"
  }
]
```

---

## ðŸ§  Arquitetura do Motor de DetecÃ§Ã£o (v9.5.0)

### Pipeline de Processamento

```
Texto de Entrada
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAMADA 1: REGEX                           â”‚
â”‚  â€¢ CPF (com validaÃ§Ã£o de dÃ­gito verificador)                 â”‚
â”‚  â€¢ CNPJ, PIS, CNS, TÃ­tulo de Eleitor (validaÃ§Ã£o DV)         â”‚
â”‚  â€¢ RG, CNH, Passaporte, CTPS, CertidÃµes                     â”‚
â”‚  â€¢ Email pessoal (exclui .gov.br, .org.br, .edu.br)         â”‚
â”‚  â€¢ Telefone (fixo, celular, DDI)                             â”‚
â”‚  â€¢ EndereÃ§o residencial, CEP                                 â”‚
â”‚  â€¢ Dados bancÃ¡rios, PIX, CartÃ£o de crÃ©dito                   â”‚
â”‚  â€¢ Placa de veÃ­culo (Mercosul e antiga)                      â”‚
â”‚  â€¢ Data de nascimento, IP Address                            â”‚
â”‚  â€¢ Texto com gatilhos de contato (ex: "falar com", "ligar para")â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAMADA 2: BERT NER (primÃ¡rio)                   â”‚
â”‚  Modelo: Davlan/bert-base-multilingual-cased-ner-hrl        â”‚
â”‚  â€¢ Detector primÃ¡rio de nomes pessoais (PER)                 â”‚
â”‚  â€¢ Threshold de confianÃ§a: 0.75                              â”‚
â”‚  â€¢ Filtros: nome + sobrenome, nÃ£o em blocklist               â”‚
â”‚  â€¢ Verifica imunidade funcional antes de marcar              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            CAMADA 3: spaCy (complementar)                    â”‚
â”‚  Modelo: pt_core_news_lg (portuguÃªs)                         â”‚
â”‚  â€¢ Captura nomes que o BERT nÃ£o detectou                     â”‚
â”‚  â€¢ Roda em paralelo, nÃ£o Ã© fallback                          â”‚
â”‚  â€¢ Evita duplicatas: sÃ³ adiciona se BERT nÃ£o encontrou       â”‚
â”‚  â€¢ Mesmos filtros de qualidade                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAMADA 4: REGRAS DE NEGÃ“CIO                     â”‚
â”‚  â€¢ Gatilhos de contato: "falar com", "ligar para"           â”‚
â”‚    â†’ Nome apÃ³s gatilho = SEMPRE PII                          â”‚
â”‚  â€¢ Imunidade funcional: "Dr. JoÃ£o da Secretaria"             â”‚
â”‚    â†’ Servidor em contexto funcional = NÃƒO PII                â”‚
â”‚  â€¢ Contexto BrasÃ­lia: SQS, SQN, Eixo = endereÃ§o pÃºblico     â”‚
â”‚  â€¢ Blocklist: saudaÃ§Ãµes, termos administrativos              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ENSEMBLE OR + DEDUPLICAÃ‡ÃƒO                  â”‚
â”‚  â€¢ Combina achados de todas as camadas                       â”‚
â”‚  â€¢ Remove duplicatas priorizando maior peso                  â”‚
â”‚  â€¢ Calcula risco mÃ¡ximo e confianÃ§a composta                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
   Resultado Final
   (classificacao, risco, confianca, detalhes)
```

### Sistema de ConfianÃ§a Composta

A confianÃ§a de cada PII detectado Ã© calculada dinamicamente:

```
confianÃ§a_final = min(1.0, confianÃ§a_base Ã— fator_contexto)
```

#### ConfianÃ§a Base por MÃ©todo

| MÃ©todo | Tipos | Base | Justificativa |
|--------|-------|------|---------------|
| **Regex + DV** | CPF, PIS, CNS, CNH, TÃ­tulo Eleitor, CTPS | 0.98 | ValidaÃ§Ã£o matemÃ¡tica |
| **Regex + Luhn** | CartÃ£o CrÃ©dito | 0.95 | Algoritmo vÃ¡lido |
| **Regex estrutural** | Email, Telefone, Placa, PIX | 0.85-0.95 | PadrÃ£o claro |
| **Regex + contexto** | CEP, Data Nascimento | 0.70-0.75 | Depende de contexto |
| **BERT NER** | Nomes | score do modelo | Retorna 0.75-0.99 |
| **spaCy NER** | Nomes | 0.70 | Modelo complementar |
| **Gatilho** | Nomes apÃ³s "falar com" | 0.85 | PadrÃ£o linguÃ­stico |

#### Fatores de Contexto

| Fator | Ajuste | Exemplo |
|-------|--------|---------|
| Possessivo | +15% | "**Meu** CPF Ã©..." |
| Label explÃ­cito | +10% | "**CPF:** 529..." |
| Verbo declarativo | +5% | "CPF **Ã©** 529..." |
| Gatilho de contato | +10% | "**falar com** JoÃ£o" |
| Contexto de teste | -25% | "**exemplo**: 000..." |
| Declarado fictÃ­cio | -30% | "CPF **fictÃ­cio**" |
| NegaÃ§Ã£o | -20% | "**nÃ£o Ã©** meu CPF" |
| Institucional | -10% | "CPF **da empresa**" |

#### Exemplos de CÃ¡lculo

```python
# Exemplo 1: CPF com possessivo e label
texto = "Meu CPF: 529.982.247-25"
base = 0.98  # DV vÃ¡lido
fator = 1.0 + 0.15 (possessivo) + 0.10 (label) = 1.25
confianca = min(1.0, 0.98 * 1.25) = 1.0  # Capped

# Exemplo 2: CPF em contexto de exemplo
texto = "exemplo de CPF: 529.982.247-25"
base = 0.98
fator = 1.0 - 0.25 (exemplo) = 0.75
confianca = 0.98 * 0.75 = 0.74  # Baixa, pode ser filtrado

# Exemplo 3: Nome detectado por BERT com gatilho
texto = "falar com JoÃ£o Silva"
base = 0.87  # Score do BERT
fator = 1.0 + 0.10 (gatilho) = 1.10
confianca = min(1.0, 0.87 * 1.10) = 0.96
```

### Tipos de PII Detectados

| Categoria | Tipos | Peso | ValidaÃ§Ã£o |
|-----------|-------|------|-----------|
| **Documentos** | CPF, RG, CNH, Passaporte, PIS, CNS, CNPJ (MEI), TÃ­tulo Eleitor, CTPS, CertidÃµes | 5 (CrÃ­tico) | DÃ­gito Verificador |
| **Contato** | Email pessoal, Telefone, Celular | 4 (Alto) | Regex + exclusÃ£o institucional |
| **LocalizaÃ§Ã£o** | EndereÃ§o residencial, CEP | 4 (Alto) | Contexto "moro", "resido" |
| **Financeiro** | Conta bancÃ¡ria, PIX, CartÃ£o de crÃ©dito | 4 (Alto) | PadrÃµes estruturados |
| **IdentificaÃ§Ã£o** | Nome completo, Nome em contexto | 3-4 | BERT NER + regras |
| **Outros** | Placa de veÃ­culo, Data nascimento, IP | 3 (Moderado) | Regex |

### Imunidade Funcional (LAI)

Servidores pÃºblicos em exercÃ­cio de funÃ§Ã£o **NÃƒO sÃ£o PII**:
- âœ… "A Dra. Maria da Secretaria de SaÃºde informou que..."
- âœ… "O servidor JosÃ© Santos do DETRAN atendeu a demanda"
- âœ… "FuncionÃ¡rio do mÃªs: Pedro Oliveira"

**Gatilhos que ANULAM imunidade:**
- âŒ "Preciso falar com o JoÃ£o Silva sobre isso"
- âŒ "Ligar para a Dra. Maria no celular"
- âŒ "EndereÃ§o da Maria: Rua das Flores, 123"

---

## ðŸ§ª Testes e Benchmark

```bash
# Na pasta backend/, com ambiente virtual ativo

# Execute o benchmark LGPD (303 casos, F1=1.0)
python benchmark.py

# Execute os testes de confianÃ§a
python test_confianca.py
```

**Benchmark LGPD (303 casos - F1-Score = 1.0000):**

| Grupo | Quantidade | Esperado | DescriÃ§Ã£o |
|-------|------------|----------|-----------|
| Administrativo | 50+ | PÃšBLICO | Textos burocrÃ¡ticos sem PII |
| PII ClÃ¡ssico | 80+ | NÃƒO PÃšBLICO | CPF, Email, Telefone, RG, etc |
| Nomes | 40+ | Variado | Nomes com contexto funcional vs pessoal |
| Edge Cases | 50+ | Variado | SituaÃ§Ãµes ambÃ­guas, BrasÃ­lia/GDF |
| Imunidade | 30+ | PÃšBLICO | Servidores em exercÃ­cio |
| Gatilhos | 25+ | NÃƒO PÃšBLICO | "falar com", "ligar para" |
| Documentos DV | 25+ | NÃƒO PÃšBLICO | CPF, CNPJ, PIS, CNS com validaÃ§Ã£o |

---

## ðŸ³ Dockerfile

```dockerfile
# Python 3.10 slim para menor tamanho
FROM python:3.10-slim

# VariÃ¡veis de ambiente
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

# DependÃªncias do sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential curl && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Instala PyTorch CPU
RUN pip install --no-cache-dir torch==2.1.0+cpu \
    --index-url https://download.pytorch.org/whl/cpu

# Instala dependÃªncias Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Baixa modelo spaCy
RUN pip install --no-cache-dir \
    https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.8.0/pt_core_news_lg-3.8.0-py3-none-any.whl

# PrÃ©-download BERT NER
RUN python -c "from transformers import pipeline; \
    pipeline('ner', model='Davlan/bert-base-multilingual-cased-ner-hrl')"

# Copia cÃ³digo
COPY . .

# Porta HuggingFace Spaces
EXPOSE 7860

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:7860/health || exit 1

# Comando de inicializaÃ§Ã£o
CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "7860"]
```

---

## ðŸ“š CÃ³digo Fonte Comentado

### Exemplo: Motor de DetecÃ§Ã£o (`src/detector.py`)

```python
class PIIDetector:
    """Detector hÃ­brido de PII com ensemble de alta recall.
    
    EstratÃ©gia: Ensemble OR - qualquer detector positivo classifica como PII.
    Isso maximiza recall (nÃ£o deixar escapar nenhum PII) Ã s custas de alguns
    falsos positivos, que Ã© a estratÃ©gia correta para LAI/LGPD.
    """

    def __init__(self, usar_gpu: bool = True) -> None:
        """Inicializa o detector com todos os modelos NLP.
        
        Args:
            usar_gpu: Se True, usa CUDA quando disponÃ­vel
        """
        logger.info("ðŸ† [v9.2] F1-Score = 1.0000 - Benchmark LGPD")
        
        self.validador = ValidadorDocumentos()
        self._inicializar_modelos(usar_gpu)
        self._inicializar_vocabularios()
        self._compilar_patterns()

    def detect(self, text: str) -> Tuple[bool, List[Dict], str, float]:
        """Detecta PII no texto usando ensemble de alta recall.
        
        Pipeline:
        1. Regex com validaÃ§Ã£o de DV (documentos)
        2. ExtraÃ§Ã£o de nomes apÃ³s gatilhos de contato
        3. NER com BERT + spaCy (nomes e entidades)
        4. DeduplicaÃ§Ã£o com prioridade por peso
        
        Args:
            text: Texto a ser analisado
            
        Returns:
            Tuple com:
            - is_pii (bool): True se contÃ©m PII
            - findings (List[Dict]): PIIs encontrados
            - nivel_risco (str): CRITICO, ALTO, MODERADO, BAIXO, SEGURO
            - confianca (float): Score 0-1 normalizado
        """
```

### Exemplo: API FastAPI (`api/main.py`)

```python
@app.post("/analyze")
async def analyze(data: Dict[str, Optional[str]]) -> Dict:
    """Analisa texto para detecÃ§Ã£o de PII com contexto BrasÃ­lia/GDF.
    
    Realiza detecÃ§Ã£o hÃ­brida usando:
    - Regex: PadrÃµes estruturados (CPF, Email, Telefone, RG, CNH)
    - NLP: Reconhecimento de entidades com spaCy + BERT
    - Regras de NegÃ³cio: Contexto de BrasÃ­lia, imunidade funcional (LAI)
    
    Args:
        data: Dict com "text" (obrigatÃ³rio) e "id" (opcional)
    
    Returns:
        Dict com classificacao, risco, confianca e detalhes
    """
```

---

## ðŸ—ï¸ Arquitetura Atualizada (2026)

O backend agora conta com trÃªs grandes pilares para detecÃ§Ã£o e explicaÃ§Ã£o de PII:

- **Pipeline HÃ­brido Original:** Regex, validaÃ§Ã£o DV, BERT Davlan, NuNER pt-BR, spaCy, gazetteer, regras, confianÃ§a probabilÃ­stica, thresholds dinÃ¢micos, pÃ³s-processamento.
- **Presidio Framework (Microsoft):** DetecÃ§Ã£o PII modular, multi-idioma, fÃ¡cil manutenÃ§Ã£o e expansÃ£o de entidades, integraÃ§Ã£o via `detect_pii_presidio`.
- **Ãrbitro LLM (Llama-3.2-3B-Instruct via huggingface_hub):** ExplicaÃ§Ã£o e arbitragem de casos ambÃ­guos, fallback para edge cases, integraÃ§Ã£o via biblioteca oficial.

O resultado final pode ser uma fusÃ£o (ensemble) dos detectores, com explicaÃ§Ã£o detalhada e mÃ¡xima cobertura.

Veja exemplos de uso das novas funÃ§Ãµes e como customizar detectores no final deste README.

---

## ðŸ¤– Arbitragem com LLM (Llama-3.2-3B-Instruct via huggingface_hub)

O backend possui integraÃ§Ã£o com Llama-3.2-3B-Instruct (biblioteca `huggingface_hub`) para arbitragem de casos ambÃ­guos de PII. **Ativado por padrÃ£o na v9.5.0**.

- Use a funÃ§Ã£o `arbitrate_with_llama(texto, achados)` para obter decisÃ£o e explicaÃ§Ã£o detalhada de um LLM.
- Ideal para casos de baixa confianÃ§a, empate entre detectores ou explicaÃ§Ã£o avanÃ§ada para humanos.
- O token Hugging Face jÃ¡ utilizado no projeto Ã© aproveitado para autenticaÃ§Ã£o.

Exemplo:
```python
from src.detector import arbitrate_with_llama

decision, explanation = arbitrate_with_llama(texto, achados)
print(decision, explanation)
```

---


## IntegraÃ§Ã£o Modular Presidio + ONNX (v9.5+)

A partir da versÃ£o 9.5, **TODO O MOTOR DE DETECÃ‡ÃƒO FOI CENTRALIZADO NO FRAMEWORK [Presidio Analyzer](https://microsoft.github.io/presidio/)**, com todos os regex e NER registrados como Recognizers customizados. Isso garante:

- **Auditoria e rastreabilidade total**: cada achado traz fonte, score, explicaÃ§Ã£o e logs.
- **ExpansÃ£o e manutenÃ§Ã£o facilitadas**: adicionar/ajustar entidades = sÃ³ registrar novo Recognizer.
- **Performance mÃ¡xima**: integraÃ§Ã£o nativa com ONNX para BERT NER (quando disponÃ­vel), fallback automÃ¡tico para pipelines originais (transformers, spaCy, NuNER).
- **PolÃ­tica de agregaÃ§Ã£o e deduplicaÃ§Ã£o**: resultados sÃ£o agregados por span, priorizando maior score e explicaÃ§Ã£o detalhada (campo `explanation`).
- **SeguranÃ§a do token Hugging Face**: Uso obrigatÃ³rio de `.env` (nÃ£o versionado), carregamento automÃ¡tico em todos os entrypoints, nunca exposto em cÃ³digo ou log.

### Como funciona

1. **Regex â†’ PatternRecognizer**: Todos os padrÃµes (CPF, CNPJ, RG, etc) agora sÃ£o PatternRecognizers do Presidio, com validaÃ§Ã£o DV opcional.
2. **NER â†’ EntityRecognizer**: BERT, NuNER e spaCy sÃ£o registrados como EntityRecognizers customizados, cada um com sua pipeline.
3. **BERT NER via ONNX**: Se o modelo ONNX estiver presente (`backend/models/bert_ner_onnx/model.onnx`), o Recognizer usa inferÃªncia otimizada via `optimum.onnxruntime`. Caso contrÃ¡rio, usa pipeline transformers padrÃ£o.
4. **AgregaÃ§Ã£o**: Todos os achados sÃ£o deduplicados por span, priorizando maior score e explicaÃ§Ã£o detalhada (campo `explanation`).
5. **Fallback e logs**: Se algum Recognizer falhar, logs detalhados sÃ£o emitidos e o sistema continua com os demais.

### Exemplo de uso: detecÃ§Ã£o PII centralizada

```python
from src.detector import detect_pii_presidio

texto = "Meu CPF Ã© 123.456.789-00 e meu telefone Ã© (61) 99999-8888."
resultados = detect_pii_presidio(texto, entities=None, language='pt')
for r in resultados:
  print(r)
# SaÃ­da: [{'entity': 'CPF', 'score': 0.98, ...}, {'entity': 'TELEFONE_DDI', ...}, ...]
```

#### Exemplo: uso avanÃ§ado com agregaÃ§Ã£o e explicaÃ§Ã£o

```python
from src.detector import PIIDetector

detector = PIIDetector()
achados = detector.detect_presidio_ensemble("Falar com JoÃ£o Silva, CPF 123.456.789-00", entities=None)
for a in achados:
  print(a['entity'], a['score'], a['explanation'])
# SaÃ­da: NOME 0.97 Detectado por ONNX_BERT_NER_Recognizer (score=0.97)
#        CPF 1.0 Detectado por PatternRecognizer (score=1.00)
```

### Como expandir: registrando novos Recognizers

Para adicionar um novo padrÃ£o ou NER:

```python
from presidio_analyzer import Pattern, PatternRecognizer, EntityRecognizer

# Exemplo: novo padrÃ£o para matrÃ­cula funcional
pattern = Pattern(name="MATRICULA_FUNCIONAL", regex=r"\b\d{7,8}[A-Z]?\b", score=0.90)
recognizer = PatternRecognizer(supported_entity="MATRICULA_FUNCIONAL", patterns=[pattern])
detector.presidio_analyzer.registry.add_recognizer(recognizer)

# Exemplo: novo NER customizado
class MeuNERRecognizer(EntityRecognizer):
  def __init__(self, nlp_pipeline, entity_label):
    super().__init__(supported_entities=[entity_label], name="MeuNERRecognizer")
    self.nlp_pipeline = nlp_pipeline
  def analyze(self, text, entities, nlp_artifacts=None):
    # ... lÃ³gica customizada ...
    return results
detector.presidio_analyzer.registry.add_recognizer(MeuNERRecognizer(...))
```

### Vantagens
- **Auditoria LGPD**: Cada achado traz fonte, score, explicaÃ§Ã£o e logs.
- **ExpansÃ£o fÃ¡cil**: Basta registrar novo Recognizer, sem alterar o core.
- **Performance**: ONNX acelera BERT NER em atÃ© 5x (CPU), sem perder precisÃ£o.
- **Fallback robusto**: Se ONNX nÃ£o disponÃ­vel, usa pipeline transformers/spaCy/NuNER.
- **AgregaÃ§Ã£o e explicaÃ§Ã£o**: PolÃ­tica de deduplicaÃ§Ã£o e explicaÃ§Ã£o detalhada por span.

### InstalaÃ§Ã£o e dependÃªncias

JÃ¡ incluso em `requirements.txt`:

```
presidio-analyzer
optimum[onnx]
onnxruntime
```

Para exportar o modelo BERT NER para ONNX:

```
pip install optimum[onnx] onnxruntime
optimum-cli export onnx --model Davlan/bert-base-multilingual-cased-ner-hrl backend/models/bert_ner_onnx/
```

Mais detalhes: [DocumentaÃ§Ã£o oficial Presidio](https://microsoft.github.io/presidio/analyzer/)

---

## ðŸ—‚ï¸ Fluxograma Arquitetural Atualizado

```mermaid
flowchart TD
  A[Texto de Entrada] --> B[Presidio AnalyzerEngine]
  B --> C1[PatternRecognizers (Regex + ValidaÃ§Ã£o DV)]
  B --> C2[EntityRecognizers (BERT NER ONNX, NuNER, spaCy)]
  C2 --> D1[ONNX BERT NER (se disponÃ­vel)]
  C2 --> D2[Transformers Pipeline (fallback)]
  C2 --> D3[NuNER Pipeline]
  C2 --> D4[spaCy Pipeline]
  B --> E[AgregaÃ§Ã£o/DeduplicaÃ§Ã£o + ExplicaÃ§Ã£o]
  E --> F[Resultado Final: achados, score, explicaÃ§Ã£o, fonte]
```

---
